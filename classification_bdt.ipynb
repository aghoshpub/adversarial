{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load signal, backgound data\n",
    "vbf_events = pd.read_hdf(\"../MC_Prod_v12/vbf_events.hdf\", \"vbf\") #do hdf5!!\n",
    "ggf_events = pd.read_hdf(\"../MC_Prod_v12/ggF_events.hdf\", \"ggF\")\n",
    "qq_events = pd.read_hdf(\"../MC_Prod_v12/qq_all_events.hdf\", \"qq_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf_events[\"class\"] = 1\n",
    "ggf_events[\"class\"] = 2 # need to reweight ggF better! set to 0 afterwards\n",
    "qq_events[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60.047187373963304, 6.0885523004705586, 8.7771621167023159)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.047187373963304"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = qq_events.weight_couplings.sum(), vbf_events.weight_couplings.sum(), ggf_events.weight_couplings.sum()\n",
    "print class_weights\n",
    "max(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.concat([vbf_events, ggf_events, qq_events])\n",
    "data = pd.concat([vbf_events, ggf_events])\n",
    "#print data.isnull().values.any()\n",
    "#data.describe()\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle the events\n",
    "target = data[\"class\"]\n",
    "mass = data[\"m4l_fsr\"]\n",
    "weights = data[\"weight_couplings\"]\n",
    "del data[\"class\"]\n",
    "del data[\"m4l_fsr\"]\n",
    "del data[\"weight_couplings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = mass.apply(np.log)\n",
    "mass_max, mass_min = mass.max(), mass.min()\n",
    "mass = (mass - mass_min)/(mass_max - mass_min) #!!! save max, min values to file\n",
    "#mass.describe()\n",
    "#plt.hist(mass)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweight Events\n",
    "Training: 1000x everything, fraction 1/3 VBF 1/3 ggF 1/3 qq ~~0.5 VBF, 0.25 ggF, 0.25 qq~~\n",
    "\n",
    "Testing: Back to original VBF, ggF, qq sum of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_size = 0.75 # 0.1 # !!!\n",
    "X_train, X_test, y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    "    train_test_split(data, target, mass, weights, train_size=train_size)\n",
    "#reset index for dataseries, not needed for ndarray (X_train, X_test)\n",
    "y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    " y_train.reset_index(drop=True),y_test.reset_index(drop=True), \\\n",
    "    mass_train.reset_index(drop=True), mass_test.reset_index(drop=True), \\\n",
    "    weights_train.reset_index(drop=True), weights_test.reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "class_weights_test = weights_test[y_test == 0].sum(), weights_test[y_test == 1].sum(), weights_test[y_test == 2].sum()\n",
    "scale_up = 1000.\n",
    "for i in xrange(3):\n",
    "    weights_train[y_train == i] *= scale_up*max(class_weights)/ class_weights[i]\n",
    "    weights_test[y_test == i] *= class_weights[i]/class_weights_test[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 44980.134015625648, 45563.100003125699)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_train[y_train == 0].sum(), weights_train[y_train == 1].sum(), weights_train[y_train == 2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 6.0885523004705577, 8.7771621167023177)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_test[y_test == 0].sum(), weights_test[y_test == 1].sum(), weights_test[y_test == 2].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ggF background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 2] = 0\n",
    "y_test[y_test == 2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "#@TODO: check other activations in Andreas, Gilles pivot\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "D.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train *=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(weights_train ==0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72115/72115 [==============================] - 6s - loss: 0.5493     \n",
      "Epoch 2/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5269     \n",
      "Epoch 3/10\n",
      "72115/72115 [==============================] - 6s - loss: 0.5229     \n",
      "Epoch 4/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5217     \n",
      "Epoch 5/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5196     \n",
      "Epoch 6/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5177     \n",
      "Epoch 7/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5165     \n",
      "Epoch 8/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5153     \n",
      "Epoch 9/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5139     \n",
      "Epoch 10/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.5125     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119673a10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10)\n",
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=1) #short for testing purposes\n",
    "#D.fit(X_train, y_train, nb_epoch=10) #unweighted training\n",
    "#D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train)) #Only interclass weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83085, 13069, 127270)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vbf_events), len(ggf_events), len(qq_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_test ==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88707116659872298"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = D.predict(X_test)\n",
    "y_pred = y_pred.ravel()\n",
    "roc_auc_score(y_true=y_test, y_score=y_pred, sample_weight=weights_test)\n",
    "#roc_auc_score(y_true=y_test, y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = D.predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_pred_test_sig = [weights_train[(y_train ==1) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "#int_pred_test_bkg = [weights_train[(y_train ==0) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "\n",
    "int_pred_test_sig = [weights_test[(y_test ==1) & (y_pred > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_test_bkg = [weights_test[(y_test ==0) & (y_pred > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x119a48b10>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd81FW+//HXmUknvUFIJaGFKhBC\nkyIIKhbswsq66yro2tdyr/e63r2/Xdu6V9deWLvroiu6LthRmiAtoXcIJJAE0hMIJKTM+f1xIljA\nDDAz35nM5/l4fB+TZL7JfL5JeHNyvqcorTVCCCF8h83qAoQQQpwaCW4hhPAxEtxCCOFjJLiFEMLH\nSHALIYSPkeAWQggfI8EthBA+RoJbCCF8jAS3EEL4mAB3fNH4+HidkZHhji8thBAdUn5+fqXWOsGZ\nc90S3BkZGeTl5bnjSwshRIeklCpy9lzpKhFCCB8jwS2EED5GglsIIXyMBLcQQvgYCW4hhPAxEtxC\nCOFjJLiFEMLHuGUc92lb/Di0Np/4ubRh0P1cz9YjhBBeyLuCe+lT0HzkBE+07Ys54jY493/BHujB\nooQQwrt4V3A/UHrij7c0wZcPwPLnoGQNXPU6RHTxbG1CCOElfKOPOyAIJv8FLv8b7F8HL4+BwmVW\nVyWEEJbwjeD+zoCr4cavITgC3rwYvn0WtLa6KiGE8CjfCm6Azn1gxkLoPRm+/D18cKOEtxDCr/he\ncAOERMLVb8PY+2HTHFj7d6srEkIIj/HN4AZQCsb+J6SNNC3v+nKrKxJCCI/w3eAGsNng4qfNEMLP\n77e6GiGE8AjfDm6AhJ4w+l7Y9AHs+NLqaoQQwu18P7gBzr4L4nvBJ/fA0XqrqxFCCLfqGMEdEGy6\nTOr2wqJHra5GCCHcqmMEN0D6CBhyPax4wcyuFEKIDqrjBDeYdUw6JcK8O6C1xepqhBDCLTpWcIdG\nw+TH4cBG0/IWQogOyKngVkr9Tim1WSm1SSk1WykV4u7CTlv2JdBrMix8BGr3WV2NEEK4XLvBrZRK\nBu4AcrTW/QA7MNXdhZ02peCCP4NuhcV/troaIYRwOWe7SgKAUKVUABAGnGT9VS8RnQY5N8C6d6By\np9XVCCGES7Ub3FrrEuD/gL3AfqBOa+39M11G3wMBobDwYasrEUIIl3KmqyQGmAJ0A7oCnZRS009w\n3kylVJ5SKq+iosL1lZ6q8AQYcQts/hfsX291NUII4TLOdJWcC+zRWldorZuBD4GRPz5Jaz1La52j\ntc5JSEhwdZ2nZ+TtEBINX//J6kqEEMJlnAnuvcBwpVSYUkoBE4Ct7i3LRUKi4Ozfwa75UPSt1dUI\nIYRLONPHvRKYA6wBNrZ9ziw31+U6uTMhvAt8/UfZcEEI0SE4NapEa/0HrXVvrXU/rfUvtdZH3V2Y\nywSFwdj7YO9y2PWV1dUIIcQZ61gzJ09m0HUQnW5a3Q6H1dUIIcQZ8Y/gDgiCcx6AAxtgy0dWVyOE\nEGfEP4IboP+VkJBtxnXLAlRCCB/mP8Fts8OEB6FqF6yTzYWFEL7Lf4IbzOJTqcPNAlSyU44Qwkf5\nV3ArBec9DPVlsOxpq6sRQojT4l/BDZCSA/2ugG+fhboSq6sRQohT5n/BDTDhD2bZ1wUPWV2JEEKc\nMv8M7ph0GHYzrJ8tC1AJIXyOfwY3mGVfQ2PgiwdkKrwQwqf4b3CHRsO4/4LCb2DHF1ZXI4QQTvPf\n4AbIuR7iesD8B6G12epqhBDCKf4d3PZAmPhHqNwB+W9YXY0QQjjFv4MboNcFkDEaFj0KjXVWVyOE\nEO2S4FYKJj0ER6ph6V+trkYIIdolwQ3Q9SyzCNXKl6G+3OpqhBDiZ0lwf2fcf0HLUWl1CyG8ngT3\nd+Ky4KxpsPpVmQovhPBqEtzfN+Y/QDvgmyesrkQIIU5Kgvv7YtJh8HWw5i2oKbS6GiGEOCEJ7h8b\ncy8oGyz+i9WVCCHECUlw/1hkVxh6A6z/B1TusroaIYT4CQnuEzn7dxAQAosfs7oSIYT4CQnuEwlP\nhGE3wcY5ULbF6mqEEOIHJLhPZuQdEBQOix6xuhIhhPgBCe6TCYuFEbfC1nlQus7qaoQQ4hgJ7p8z\n4hYIiZYtzoQQXkWC++eERJkblbvmw54lVlcjhBCABHf7ht0EkSkw/3/A4bC6GiGEkOBuV2AojH8A\nStfC5g+trkYIISS4nTLgGujcD77+o1lBUAghLCTB7QybHSb+P6gtgrzXrK5GCOHnJLidlTUBMsfB\n4sehodbqaoQQfkyC21lKmY2FG6ph2VNWVyOE8GMS3KciaaDp717xItQVW12NEMJPSXCfqvG/N5st\nLJSp8EIIazgV3EqpaKXUHKXUNqXUVqXUCHcX5rWi08zY7nX/gLLNVlcjhPBDAU6e9zTwudb6SqVU\nEBDmjmIG/2k+DU2tJ33eblMoZR5tyhwBNkVokJ3QQPuxx5BAO+HBdjpHhpAUFUJSdChdo0JJig4h\nrlMQSqkzK3T0PbDmbTMpZ/oHZ/a1hBDiFLUb3EqpKGAM8GsArXUT0OSOYqYOTaXFoU/4nNYah4ZW\nh0ZrTWvb+80tDhpbHDQ0tdLY3MqRphaqDjdRf7SZsrqjNLX+cLZjUICNrlEhJMeEkhwdSnJ0GMkx\noXSNDiE1JoykqBAC7O38IRIaY8J7/oOw5xvoNtpV3wIhhGiX0vrEQXnsBKXOAmYBW4CBQD5wp9b6\n8Mk+JycnR+fl5bmyztOitabqcBP7axsprWtgf20D++saKaltMEdNA+WHfjihxm5TdIkMITU2lJSY\nMFJjwkiLCyUzPpzMhE5EhASaE5sb4JnBEJ0Kv/nCjDoRQojTpJTK11rnOHWuE8GdA6wARmmtVyql\nngYOaq0f/NF5M4GZAGlpaUOKiopOq3hPO9rSyv5aE+bFNUcormlgX7V5LK5poOxQI9//FiVGBJOZ\n0InMhHAmH/2cs7c9RMXFbxE36BJsNglvIcTpcXVwdwFWaK0z2t4fDdyvtb7wZJ/jLS1uV2hsbqW4\n5ggFFYcpqKhnd8VhdlfUs7vyMPVHGpgfdB+NBHOZ4zEy4iPISgyne0I4fbpG0i85iq5RIWfepy6E\n6PBOJbjb7ePWWh9QSu1TSvXSWm8HJmC6TfxCSKCd7okRdE+M+MlzVfVHqV1VQ/aSO3m0+y7mOUay\nqaSOzzbu57uu+piwQPolR9G3axT9kiPpkxRJelwn7NI6F0KcpnZb3HCsn/sVIAjYDVyvta452fkd\nqcXdLocDXjobWhrg1lVgD6ShqZWtBw6yuaSOzaUH2VRax/YDh2huNd/r0EA7vZMiyE4yQZ6dFEl2\nUgRhQc4O8hFCdDQu7So5HX4V3ADbP4PZU+Hip2HIr094SlOLgx1lh9iy/yBb9x9kS6l5PNjYAoBN\nQY/ECPqnRDEgJYoBKdH07hJBSKDdgxcihLCKBLenaQ2vTjLT4O9YC4EhTn6apqS2gS2lB9lUepCN\nxbVsKK6j6rAZbRlgU2QnRZKTEcPQjFhy0mNIjHTuawshfIsEtxX2fANvXgSTHoaRt532l9FaU1rX\nyMbiWtYX17F2bw3r9tXS2GzGo6fHhZGTHktutxhGZsWTGuuWuVBCCA+T4LbKW5fC/vVw53oIiXTZ\nl21qcbBl/0HyCqtZXVhNXmHNsVZ5WmwYo7rHMTIrnpFZccSFB7vsdYUQniPBbZWSNfC3c2Dcf8G4\n+932MlprCirqWbarimW7Klm+u4pDbX3l2UmR5GbEkJMRS05GDElRoW6rQwjhOhLcVnpvOhQsMn3d\n4QkeecmWVgebSg+ybFcl3xZUsnZvLUfa1nxJjg4lJyOGnPQYBqXF0KtLBIHtTekXQnicBLeVKnaY\n4YFZ42HabEumwre0Oti6/xCrC6vJL6phdWH1san9wQE2+naNZGBqNGelRjMwJZr0uDCZJCSExSS4\nrbbiRfj8frjwCRh6o9XVoLWmuKaBdftqWb+vlvXFtWwsqTt2wzO2UxBD20auDOsWR3ZSRPsLbQkh\nXEqC22oOB7xzJRQtg5mLIbG31RX9REurgx1l9awvriWv0LTK91YfAaBTkJ3B6THkZsQyOD2GASlR\nxxfXEkK4hQS3NzhUBi+OgIiuMONrCPD+0R4H6hpZVVjN6j3VrNpTzfayQ4Dp7enVOYJBadEMSoth\ncFo0mfHhsqiWEC4kwe0ttn8Os6+BEbfBeQ9bXc0pq2toZv2+WtbsrWHN3lrW7a05NtMzOiyQwWkx\nDEk3x8CUaEKDZJanEKfLpYtMiTPQ63zTx738OXOzsvsEqys6JVGhgYzpmcCYnmZ0jMOh2V1ZT35R\nDWuKaskrqmbBtnLAzPLs0zWSYd1iGZEVR05GLJHSvSKEW0iL292aG+DlsdBYC79dDp3irK7IpWoO\nN7F2Xw15heZYt6+WplYHNgX9k6MYnhXH8Mw4hmbEEh4s7QQhTka6SrzNgY3wt/HQ/VyY+o8OvVtO\nY3Mra4pqWLG7iuW7q1i3r5bmVo3dpuifHMWItiDPSY+hkwS5EMdIcHuj5c/DF/8NU16AQddaXY3H\nNDS1kt8W5CvagrzFoQmwKQakmCAf1T2eIekxBAdIH7nwXxLc3sjhgNfaVhC8fQ0E+efiUEeaWsgv\nqmF5gWmRbyiuo9WhCQm0kdstjrO7myDP7hIpo1aEX5Hg9lZF38LrF8D4B2HMvVZX4xUONTazcnc1\nS3dVsmxXJTvL6wGzc1BORiy5GbEM7RZL366RMlVfdGgS3N5s9i9gzxK4cx10ire6Gq9TdrCxbc2V\nKlYXVlNUZSYFhQXZGZQWTW5GHMMzYzkrLVq6VkSHIsHtzSp2wAvDzTDByY9bXY3XKz/4vUlBhTVs\nO3AQrSEk0MaQ9BhGZJqbnQNSogkKkBa58F0S3N5u3l2w9m2zR2VcltXV+JS6I82s3GP6x5cXVLHt\ngJndGRZkZ2RWHOf0TmR870RZzlb4HAlub3eoDJ4ZBD0nwVVvWF2NT6s+3MTK3VV8W1DFwu3lFNc0\nANC7SwTjeycyITuRs1JjsMuNTuHlJLh9wcJHYPGf4cavIcWpn5Voh9aaXeX1LNhWzoJt5eQV1dDq\n0EQEBzC0WyzDM2MZnhlHn6RIWf1QeB0Jbl9w9JBpdcf3hF9/0qEn5VilrqGZb3ZWsLzAjCEvqDgM\nQHhwAEMzYhiWGUdut1j6J0fJiBVhOVmrxBcER5jtzT65B3Z8Dr0usLqiDicqNJCLBnTlogFdASg/\n1MjK3dXHZnUu3F4BQGhg24iVbrHkdotlUGqMLJglvJq0uK3U2mxGmNgC4OZlYJf/Rz2p4tBR8gqr\nWdm2jO3WthErgXbFgJTjQZ6THiPrkQu3k64SX7J1ntmn8uKnYcivra7Gr9U1NLOmqIaVe6pZuaeK\njcV1tDg0NgV9u0YxrFsso7rHk9stVtZZES4nwe1LtIbXJ0P5FjM8MKKz1RWJNkeaWlhTVMuqPVWs\n2FPNur1m5cNAu2JQWgyju8czqkc8A5Kj5GanOGMS3L7muw2Ge54H17xtdTXiJBqbW1ldaKbnL91Z\nyebSgwBEhAQwpkcC43snMq5XAnHh3r/bkfA+Ety+aOlf4av/havehL6XWl2NcEJV/VG+Lajim50V\nLNpeQfmhoygFg1KjGd87kfG9O5OdFIGSEUPCCRLcvqi1BV6ZAAdL4JaVHW7DhY7O4dBsLj3YNoa8\njPXFdQAkRYUwrlci5/RKYFT3eOkbFyclwe2ryjab3XL6XgZX/M3qasQZKD/YyMLt5SzcVsHSXZXU\nH20hyG5jWGYs43qZafnd4jtZXabwIhLcvmzho7D4MZj2ntmzUvi8phYHeYXVJsi3V7CrbenaHonh\nTOrbmUl9utA/OUrWH/dzEty+rKUJZo2Fhhq4ZQWERltdkXCxfdVH+GprGV9uLmNVYTWtDk2XyBAm\n9unMxD6dGZ4ZJysd+iEJbl9Xssb0dw+aDpc8a3U1wo1qDjexYFs587eUsXhHBQ3NrYQHBzC2VwIT\nszszrlcC0WFBVpcpPECCuyOY/wdY9hT88l+QNd7qaoQHNDa3snRnJV9tLeOrreVU1h/FblPkpMcw\nsU9nLhyQJMvVdmAS3B1BcwO8NNo83rRYdsvxMw6HZn1xLV9tLePrreVsO3AIpWBEZhyXDkrmgn5d\nZBp+ByPB3VGUroNXJ0HacJj+oaxl4sf2VB7m3+tK+NfaEoqqjhAcYOPcPp257KxkxvZKkNUNOwC3\nBLdSyg7kASVa64t+7lwJbhda+w78+xYYdSdM/KPV1QiLaa1Zu6+Wj9aWMG99KTVHmonrFMSUs5K5\nYkgyfbtGWV2iOE3uCu67gRwgUoLbwz6+G/Jehavfgj5TrK5GeInmVgeLt1fwwZpivt5aTlOrg+yk\nSK4YnMylg5KJl6n3PsXlwa2USgHeBB4G7pbg9rCWJnhjMpRvNTvmJPa2uiLhZWoONzFvQykf5Bez\nvrgOu01xTq9Epg5NZVyvBFkEywe4I7jnAI8CEcC9EtwWOFgKL4+BkCiYscA8CnECO8sOMSe/mA/W\nlFBZf5TOkcFcNSSVq3NSSYsLs7o8cRIuDW6l1EXAZK31LUqpcZwkuJVSM4GZAGlpaUOKiopOuXDR\njsJl8ObF0PN8uObvYJNWlDi55lYHC7aV897qfSzaXo5Dw6jucfwiN53z+3WRDZS9jKuD+1Hgl0AL\nEAJEAh9qraef7HOkxe1GK16Ez++H8Q/CmHutrkb4iNLaBubkF/Pe6n2U1DaQERfGTWOzuHxwMsEB\nsk2bN3DbcMCfa3F/nwS3G2kNH86AjXNg2ruynok4JQ6H5sstB3hhUQEbiuvoHBnMjWdn8othabJy\nocVOJbjlb21foxRc/AwkDYQPboCyLVZXJHyIzaY4v18S/751FG/fkEtmfDgPf7qVkY8t4Mn5O6g5\n3GR1icIJMgHHVx0shVnnQEAQzFgoMyvFaVuzt4YXFxUwf0sZYUF2fjk8nRtGdyMxIsTq0vyKzJz0\nFyX5Zr/KroPgun9DgIzbFadv24GDvLCwgI83lBJotzF1aCozx2aRHC3ro3iCBLc/2TjHdJmcNR2m\nPGe6UoQ4A3sqD/Piol18uKYEpeDyQSncek53GUroZhLc/mbhI7D4zzDxTzDqDqurER1Ecc0RZi3Z\nzbur9+FwaK4YnMJt47uTGisB7g4S3P7G4YA5v4Ytc2WkiXC5soONvLiogH+s3ItDa64emsqt53SX\nLhQXk+D2R01H4PXzoaoAfjUPkgdbXZHoYPbXNfDCwgLeXb0XgKlD07jlnCxZI9xFJLj9VV0JvHY+\nNNaaZWBTh1pdkeiASmobeH7hLt7P24dSil/kpvHbcVl0jpRRKGdCgtuf1e4z0+IPV8C170P6SKsr\nEh1Ucc2RtgAvxm5TXDssnZvHZcowwtMkwe3vDu6Hty6BumKYNhsyx1ldkejA9lYd4dkFO/lwbQmB\ndsX0YencPC5LlpU9RRLcAurL4a0pps976jvQY6LVFYkOrrDyMM8s2MlHa0sIDrBz3Yh0ZozJlAB3\nkgS3MA5XwduXQsU2uOoN6H2h1RUJP1BQUc9zC3bx73VtAT4ynZmjM4mTAP9ZEtziuIYa+PsVsH89\nXPUmZP/s+mBCuMyu8nqeW7CTf68vJTTQznUjMpg5JpPYTkFWl+aVJLjFDzUehLcvg7JNZqhgaq7V\nFQk/squ8nmcX7GTu+lLCAu3MHJPFjaO7yWqEPyLBLX7qcCW8OhEaauHGryAuy+qKhJ/ZVX6IJ+fv\n4NONB4gPD+KOCT2YOjSNoABZpBRkWVdxIp3i4do5Zi2Tv18B9RVWVyT8TPfECF64dgj/umUkWQnh\n/M+/NzPxr4uZt74Uh8P1DciOTILbn8RlwbT34NABmD3VzLYUwsMGpcXw7szhvH79UEID7dw+ey1T\nnl/G0p2VVpfmMyS4/U3qULjiFbMk7Ac3gqPV6oqEH1LK7EL/yR2jefLqgVQfbmL6qyv55asr2VRS\nZ3V5Xk+C2x9lXwQX/Bm2f2L2r3TDfQ4hnGG3KS4fnMLX94zl9xdms6mkjoueXcods9dSVHXY6vK8\nltzW9VfDboLavbD8OQjvLBsPC0uFBNq5cXQmVw9NZdbi3byydDefbtzPtcPSuGNCDxkD/iMyqsSf\nORzwr5mw8X0YfitMeghs8keYsF75wUae/non767eR6cgO/dM6sW1w9IIsHfc308ZVSKcY7PBZS9D\n7k2w4nmzk07LUaurEoLEyBAevqw/X9w1mgEp0fxh7mYuenYpK3dXWV2aV5Dg9nc2u+nvnvhH2Pyh\nGSrYUGt1VUIAZgjh2zfk8uK1gznU2MI1s1Zwx+y1HKhrtLo0S0lwCzO2e9SdcNks2LvcbEB8sNTq\nqoQAzAiUC/on8dXdY7ljfHc+33yA8U8s4pVvdvvt+G8JbnHcwGvMGt61e+GViVC+1eqKhDgmNMjO\n3ZN68dXvxjI8M46HPtnKtL+toLjG/+YjSHCLH8oaD9d/Co5meOVcWDnL3MQUwkukxYXx6q9yePzK\nAWwuPcj5T33D+3n7cMdAC28lwS1+KmkA3Pi1WYzqs/vgtfOgfJvVVQlxjFKKq3NS+ezO0fTtGsl9\nczYw8+18Kuv94+a6BLc4sehUs2/lZS9D1U546WxY9JiMOhFeJTU2jNkzhvP7C7NZvKOC8/66hPlb\nyqwuy+0kuMXJKQUDp8Ktq6HvpbDoUXh5DOxbZXVlQhxjsyluHJ3JvNvOpktUCDPeyuPxz7fR2oFv\nXEpwi/aFJ5j1TX7xTzhaD69Ognl3wpFqqysT4pheXSL48JaRTMtN44VFBfz69VXUHG6yuiy3kOAW\nzut5Hty6AobfAmvehmeHwJq35Oal8BrBAXYevbw/j13en5W7q7no2aUdctEqCW5xaoIj4PxH4OZv\nIKE3zL0dXptktkYTwktMzU3j/ZtHoLXmihe/ZU5+sdUluZQEtzg9nfuaYYOXvgQ1hTBrHHx6n9nj\nUggvMDA1mnm3n82Q9BjufX89D360qcP0e0twi9OnFJw1DW7Lg6E3wupX4JnB5rG1xerqhCAuPJi3\nfpPLzDGZvL2iiHvfX98hwluCW5y50GiY/Be4aYlpiX9yD7w8GnYvsroyIQiw2/jvydncO6kn/1pb\nwn0dILwluIXrdOlvdpG/+m1oqoe3psC710L1bqsrE4Lbxvfgnok9+XBtCffN8e3wlo0UhGspBX0u\ngR6TzFKxS56A54fBsJth9D2mdS6ERW6f0AMNPDl/BwrF41cOwG5TVpd1yqTFLdwjMMQE9e350P8q\n+PZZeGYQrHwZWputrk74sTsm9OB35/bkgzXF/OcHG3yy5d1ucCulUpVSC5VSW5RSm5VSd3qiMNFB\nRCbBpS/ATYuhSz/47D/gheGw7RPZ61JY5s5ze3DXuT2Yk1/M/R9s8LnlYZ1pcbcA92it+wDDgVuV\nUn3cW5bocJIGwnVzYdp7oGzw7i/gzYuhON/qyoSfuuvcntw5oQfv5xfz9Nc7rS7nlLQb3Frr/Vrr\nNW1vHwK2AsnuLkx0QEpBr/Pht9/C5P+D8i3wynh4/ULY/rnMwBQed9e5PbhySArPLNjJwu3lVpfj\ntFPq41ZKZQCDgJXuKEb4CXsg5M6AO9bBeY+YCTyzr4EXhkH+m9Ds39tSCc9RSvGnKf3o3SWSu95d\nx75q39iUwengVkqFAx8Ad2mtD57g+ZlKqTylVF5FRYUraxQdVUgkjLgV7lwHV7wKASEw7w54qh8s\n+YvsfSk8IjTIzkvTB+PQmlveWUNjc6vVJbVLObNrhFIqEPgY+EJr/WR75+fk5Oi8vDwXlCf8itZQ\n+A0sewZ2zYfgSMidaRa16hRndXWig5u/pYwZb+UxLTeVRy8f4PHXV0rla61znDnXmVElCngV2OpM\naAtx2pSCbmNg+hy46Ruzjdo3T8BT/eHL38Ohjr9AvrDOxD6duWVcFrNX7eOfefusLudnOdNVMgr4\nJTBeKbWu7Zjs5rqEv0saAFe/CbesgOyLYPnzJsA/uRcqfWsEgPAdd0/sycisOB78aBObS713OVin\nukpOlXSVCJerKoBlT8G62WYj425jIOcG6H2hudkphItU1h/lomeWEhRgY95tZxMV5pnfL5d2lQjh\nFeKy4JJn4e4tMP5BqN4D7/8K/toPFjwMdR1rvWVhnfjwYJ6/djCltQ08/oV3bpItwS18S3gijLkX\n7lxvJvMkDTAjUJ7qD29cBCteglrv7p8U3m9IegxTc1N5b/U+rxwiKMEtfJPNbibzXPu+CfHR98Lh\nSvj8P81wwpfHwOK/QNkWmVovTsvt43tgtymvnFUpfdyiY6kqgG0fw9aPoXg1oCE2y6xY2GcKJJ1l\nRq8I4YSHPt7Ca8v2MP/usWQlhLv1tU6lj1uCW3Rchw7A9k9hy1zYswR0K0SnQXZbiCfngE3+6BQn\nV1l/lDGPL2RCdmeenTbIra8lNyeFAIjoAjm/ges+gvt2wZTnISHbLC376kR4ZqBZblb2yRQnER8e\nzPWjMpi3vpSt+38yYdwyEtzCP4TFwqDpcO0/4T8K4LJZEJVqJvY82Qc+/h2Ue+cIAmGtmaOziAgJ\n4K/zd1hdyjES3ML/hETBwGvMLvU3LYG+l8Pad8wiV29dCts+lc2OxTFRYYHMGJ3Jl1vK2FDsHevn\nSHAL/5Y0EC59/vj48Irt8O40eDIbvnjAjEoRfu/6URnEhAXyxJfe0eqW4BYCoFO8GR9+1wa45h1I\nzYWVL8GLI+DlsaZf/HCV1VUKi0SEBHLz2CwW76hgdWG11eVIcAvxA/ZAszbK1Hfgnu1w/mOgHWbL\ntSd6wZzfQOEyGRvuh64bkUF8eDB/+WI77hiNdyokuIU4mU7xMPy3cPM3cPMyGHoD7PwK3phs9s1c\n+TI0eu9CRMK1QoPs3HZOFqv2VLNsl7V/fUlwC+GMLv3ggj/DPdvgkucgMKytFd4b5t4OuxdDS5PV\nVQo3mzYsjS6RIby+bI+ldQRY+upC+JqgMBj8S3OUroXVr8LGObDmLbPxQ9Z46Hk+9JhoWuyiQwkO\nsHNO7wQ+3XgAh0Njs1kzC1eCW4jT1XUQTHnO9IPvWQw7PocdX8CWjwAFKUOh5yQT5J37yVT7DmJw\nWgyzV+1jd2U93RMjLKlBglt1T8XFAAAKsElEQVSIMxUcbtYF732h2an+wHoT4Ds+hwUPmSMy2bTC\ne5wHmWMhqJPVVYvTNCQ9BoC8whoJbiE6BJvNtMS7DoJx95vt1nbNNyG+8QPIfwPswZA2zJyTNNAs\nfBXTTdZN8RHd4jsRExZIflENU3PTLKlBglsId4robKbaD5publ7u/RZ2fAlFy2DFi9DadkMzKMKs\nLZ48xCyClZIjXSteSinFkPQY8vdat8aNBLcQnhIQBJnjzAEmyCu2wv71x4+VL8G3z0B0OvS/Evpd\nCZ37WFezOKHB6TF8tbWc6sNNxHYK8vjrS3ALYZWAoLaukoHHP9ZYZ9YS3zQHlv7V7HKf2Af6XQ7d\nxppzA4Ktq1kAMCTN9HOv3VvDhOzOHn99CW4hvElIFAy61hz1FWaEysb3zQ1OHgJ7EHQZYKbkpww1\nR1SKdKt42ICUaAJsivwiCW4hxPeFJ0DuDHMcKoPiVbBvFRTnQd5rsOIFc15kCmSMgvS2Iy5LgtzN\nQoPs9O0aSX6RNf3cEtxC+IKIzpB9sTkAWpuhbJMJ8qJvoWABbHjPPBfeGdJHQsZo058emylB7gaD\n02OYvWovza0OAu2eHREkwS2EL7IHHh92OOwms+hV5U4oWmqCvHAZbP6XOTcq1YwdzzwHuo2B8ERr\na+8ghqTH8PqyQrbuP8iAlGiPvrYEtxAdgVKQ0NMcOb8xQV5VALsXmlmdW+fB2r+bcxOyIXUopOSa\nvvK4HjKG/DR8NxEnv6hGglsI4QJKQXx3c+TOAEerGW64e5FpkW+Za9ZXAXNDNDkH0oZD1gTTipcg\nb1dSVChdo0LIL6rh+lHdPPraEtxC+AObHZIHm2P03WZqftUuKF7ddtNzNSx8BBY+DGHx0P1cs85K\n1ngIjbG6eq81OD2GNRbcoJTgFsIf2WzHu1YGXWs+dqQadn0NO780x4Z3QdlMl0ryYEjoDYnZkNDL\ntNIFQ9Jj+HjDfkprG+gaHeqx15XgFkIYYbEw4CpzOFqhJN8EeMECyHsdWhqOnxvRFRJ7Q+e+0Lk/\ndOkP8T3MTVM/8l0/95q9NRLcQgiL2ezmxmVqLoz/velaqS2Cim1QvvX448pZ0HrUfI492IR5l/5m\n4azkwSbUAzw/JdxTspMiCQm0kV9Uw0UDunrsdSW4hRDts9kgtps5el1w/OOtLVC1Ew5sPH5s//z4\nCBZ7sJmmn5JjFtBKHgzRGR3m5meg3cbAlGiP93NLcAshTp89wPR7J2bDgKvNx7SGgyVtNz7zTJdL\n3uvHZ3oGhkF8T7MGS2JvMzwxMdtnp+4PSY9h1pLdNDS1Ehpk98hrSnALIVxLKRPCUSnQ9zLzsdZm\nKN8CpeuOd7MULID1/zj+eZ0STas8ZYgZnpg82Cdugg5Jj6HFodlQXMuwzDiPvKYEtxDC/eyBP10J\nEaChBsq3men7Jfnm2PFZ25PK3PCM6wHRqW3/GaS2vZ1m9vT0ghb6oLaVAvP31khwCyH8QGgMpI8w\nBzPMxxpqoXQNFOebx5o9sGcJNB364ecGdjLrsMR2a3tsOxKzPbpRc2ynIDITOnm0n1uCWwjhXUKj\nzcSfrPHHP6Y1NNZCXTHU7oO6fVBTCNW7TbfL9s/A0Xz8/LgeZiZo2gjz6OaFtoakxfDV1jK01igP\n/BXgVHArpc4HngbswCta68fcWpUQQnyfUqZ1Hhpjhhv+mKPVhHp1gRnZUrQctn0Ma982z3dKNCNb\nolIgIgkiux5/jOx6xps3D0mP4f38YvZUHiYzIfyMvpYz2g1upZQdeB6YCBQDq5VSc7XWW9xdnBBC\nOMVmh5h0c2SNh1F3mrHnlTvMPp97V5i1WgqXwdG6n35+WDzEZBw/YruZ7eMiu5plcoN/PoyP7fxe\nVOMdwQ3kAru01rsBlFLvAlMACW4hhPey2cxww8TeZsXE7xyth0P74WBp22MJ1BSZrpfi1WY5XN36\nw68VGGaWww3vbB4jkyE6zYR7TDpZUWlEhgSwpqiGq3NS3X5pzgR3MrDve+8XA8PcU44QQrhZcDgE\n9zAjVk6ktdl0u9QUwqEDcLgc6suhvsw8Vu6EgkU/uFlqA761RbB7Sypcsdztl+Cym5NKqZnATIC0\ntDRXfVkhhPAse+DxWaIno7UZylhTCLV7obaI/ds301h/BIdDY7O59walM8FdAny/7Z/S9rEf0FrP\nAmYB5OTkaJdUJ4QQ3kgpsyhXWKyZKAT0GOW5l3dmwYDVQA+lVDelVBAwFZjr3rKEEEKcTLstbq11\ni1LqNuALzHDA17TWm91emRBCiBNyqo9ba/0p8KmbaxFCCOGEjrG2ohBC+BEJbiGE8DES3EII4WMk\nuIUQwsdIcAshhI9RWrt+roxSqgIoOs1PjwcqXViOL5Br7vj87XpBrvlUpWutE5w50S3BfSaUUnla\n6xyr6/AkueaOz9+uF+Sa3Um6SoQQwsdIcAshhI/xxuCeZXUBFpBr7vj87XpBrtltvK6PWwghxM/z\nxha3EEKIn2FZcCulzldKbVdK7VJK3X+C54OVUu+1Pb9SKZXh+Spdx4nrvVsptUUptUEp9bVSKt2K\nOl2pvWv+3nlXKKW0UsrnRyA4c81KqavbftablVL/8HSNrubE73aaUmqhUmpt2+/3ZCvqdBWl1GtK\nqXKl1KaTPK+UUs+0fT82KKUGu7wIrbXHD8zysAVAJhAErAf6/OicW4CX2t6eCrxnRa0evN5zgLC2\nt3/ry9fr7DW3nRcBLAFWADlW1+2Bn3MPYC0Q0/Z+otV1e+CaZwG/bXu7D1Bodd1neM1jgMHAppM8\nPxn4DFDAcGClq2uwqsV9bANirXUT8N0GxN83BXiz7e05wASllHv3A3Kfdq9Xa71Qa32k7d0VmJ2G\nfJkzP2OAPwF/Bho9WZybOHPNM4DntdY1AFrrcg/X6GrOXLMGItvejgJKPVify2mtlwDVP3PKFOAt\nbawAopVSSa6swargPtEGxMknO0dr3QLUAXEeqc71nLne77sB8z+2L2v3mtv+hEzVWn/iycLcyJmf\nc0+gp1JqmVJqhVLqfI9V5x7OXPP/AtOVUsWYdf1v90xpljnVf++nzGWbBQvXUEpNB3KAsVbX4k5K\nKRvwJPBri0vxtABMd8k4zF9VS5RS/bXWtZZW5V7TgDe01k8opUYAbyul+mmtHVYX5qusanE7swHx\nsXOUUgGYP7GqPFKd6zm14bJS6lzgAeASrfVRD9XmLu1dcwTQD1iklCrE9AXO9fEblM78nIuBuVrr\nZq31HmAHJsh9lTPXfAPwTwCt9XIgBLOmR0fl1L/3M2FVcDuzAfFc4Fdtb18JLNBtPf8+qN3rVUoN\nAl7GhLav93tCO9esta7TWsdrrTO01hmYfv1LtNZ51pTrEs78Xn+EaW2jlIrHdJ3s9mSRLubMNe8F\nJgAopbIxwV3h0So9ay5wXdvokuFAndZ6v0tfwcI7s5MxrY0C4IG2j/0R848XzA/3fWAXsArItPpu\nspuv9yugDFjXdsy1umZ3X/OPzl2Ej48qcfLnrDBdRFuAjcBUq2v2wDX3AZZhRpysAyZZXfMZXu9s\nYD/QjPkL6gbgZuDm7/2Mn2/7fmx0x++1zJwUQggfIzMnhRDCx0hwCyGEj5HgFkIIHyPBLYQQPkaC\nWwghfIwEtxBC+BgJbiGE8DES3EII4WP+P+hgQzcCpSY9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e4caad0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),int_pred_test_sig)\n",
    "plt.plot(np.linspace(0,1,num=50),int_pred_test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import amsasimov\n",
    "vamsasimov = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_test_sig,int_pred_test_bkg)]\n",
    "significance = max(vamsasimov)\n",
    "threshold = np.linspace(0,1,num=50)[ np.array(vamsasimov).argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.1974723438991464, 0.91836734693877542)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1197bf490>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3EVEstD/B5LmdCScEaYYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11986fe10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),vamsasimov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiJZQgFfRCRLKOCLiGSJ/w/jE1HGlPze/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c7ef7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util_func import compare_train_test\n",
    "compare_train_test(y_pred_train, y_train, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mass_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(y_pred[mass_test<mass_test.mean()], weights=weights_test[mass_test<mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[mass_test>=mass_test.mean()], weights=weights_test[mass_test>=mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "#plt.hist(y_pred[mass_test<mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "#plt.hist(y_pred[mass_test>=mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()# @TODO: do sep for signal background, plot mass : full mass dist, vs after cut on bdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "signal_low = list (set( np.where(y_test==1)[0] ) & set( np.where(mass_test<mass_test.mean())[0]))\n",
    "signal_high = list (set( np.where(y_test==1)[0] ) & set( np.where(mass_test>=mass_test.mean())[0]))\n",
    "\n",
    "plt.hist(y_pred[signal_low], weights=weights_test[signal_low], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[signal_high], weights=weights_test[signal_high], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.title(\"Predicted scores for VBF events for low and high mass\")\n",
    "plt.ylim(0, 8)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bkg_low = list (set( np.where(y_test==0)[0] ) & set( np.where(mass_test<mass_test.mean())[0]))\n",
    "bkg_high = list (set( np.where(y_test==0)[0] ) & set( np.where(mass_test>=mass_test.mean())[0]))\n",
    "\n",
    "plt.hist(y_pred[bkg_low], weights=weights_test[bkg_low], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[bkg_high], weights=weights_test[bkg_high], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.title(\"Predicted scores for background events for low and high mass\")\n",
    "plt.ylim(0, 4)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEWCAYAAACaBstRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEhkChoiIhKZgoaIiET2/wPXNk/0YwZSXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x119b7bc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def getGevMass(mass):\n",
    "    return np.exp (mass * (mass_max - mass_min) + mass_min)\n",
    "plt.hist(getGevMass(mass_test), weights=weights_test, bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[y_pred >= threshold]), weights=weights_test[y_pred >= threshold], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score > \" + str(threshold))\n",
    "\n",
    "plt.title(\"Mass Distribution (s+b)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros((len(mass_test),), dtype=[('mass',np.float64),('weight',np.float64),('NN_score',np.float64),('y',np.float64) ])\n",
    "temp['mass'] = np.array(getGevMass(mass_test))\n",
    "temp['weight'] = np.array(weights_test)\n",
    "temp['NN_score'] = np.array(y_pred)\n",
    "temp['y'] = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.10/06\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from root_numpy import array2tree\n",
    "tree = array2tree(temp)\n",
    "\n",
    "from ROOT import TEfficiency, TH1F\n",
    "bins = 50\n",
    "scoremin = temp['mass'].min()\n",
    "scoremax = temp['mass'].max()\n",
    "hsignal = TH1F(\"hsignal\", \"mass distribution Signal\", bins, scoremin, scoremax)\n",
    "hsignal.Sumw2()\n",
    "hNN = TH1F(\"hNN\", \"mass distribution for NN Score > \" + str(threshold), bins, scoremin, scoremax)\n",
    "hNN.Sumw2()\n",
    "#tree.Project(\"hpreselect\", \"mass\", \"weight\" ) #Tefficiency can;t do weights\n",
    "tree.Project(\"hsignal\", \"mass\", \"(y==1)\" )\n",
    "#tree.Project(\"hNN\", \"mass\", \"weight*(NN_score>=\" +str(threshold) + \")\" )\n",
    "tree.Project(\"hNN\", \"mass\", \"(NN_score>=\" +str(threshold) + \")\" )\n",
    "\n",
    "print TEfficiency.CheckConsistency(hNN, hsignal)\n",
    "pEff = TEfficiency(hNN, hsignal)\n",
    "\n",
    "from ROOT import TCanvas\n",
    "c = TCanvas(\"myCanvasName\",\"The Canvas Title\",800,350)\n",
    "pEff.SetTitle(\"Unweighted Efficiency: True Signal vs Post NN Selection;Mass (GeV) ;#epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ROOT import TFile\n",
    "rfile = TFile(\"temp.root\", \"RECREATE\")\n",
    "#pEff.Write()\n",
    "#rfile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1030"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pEff.Write()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfile.Close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEff.Draw(\"AP\")\n",
    "#ROOT.enableJSVis()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(getGevMass(mass_test[y_test==1]), weights=weights_test[y_test==1], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[(y_test==1) & (y_pred >= threshold)]), weights=weights_test[(y_test==1) & (y_pred >= threshold)], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(round(threshold,2)))\n",
    "\n",
    "plt.title(\"VBF Events\")\n",
    "plt.xlabel(\"Mass (GeV)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(220,800 )\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(getGevMass(mass_test[y_test==0]), weights=weights_test[y_test==0], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[(y_test==0) & (y_pred >= threshold)]), weights=weights_test[(y_test==0) & (y_pred >= threshold)], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(round(threshold,2)))\n",
    "\n",
    "plt.title(\"Background Like Events (qq, ggF)\")\n",
    "plt.xlim(220,800 )\n",
    "plt.xlabel(\"Mass (GeV)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred)\n",
    "print \"Unweighted correlation of all test events with mass is\", corr\n",
    "\n",
    "corr = pearsonr(mass_test[y_test ==1], y_pred[y_test ==1])\n",
    "print \"Unweighted correlation of signal test with mass is\", corr\n",
    "\n",
    "corr = pearsonr(mass_test[(y_pred > threshold) ], y_pred[(y_pred > threshold)])\n",
    "print \"Unweighted correlation of all test events passing cut with mass is\", corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(y_pred>0.5).sum()/float(y_pred.shape[0]) # much better than without class_weight training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "\n",
    "def make_trainable(network, flag):\n",
    "    network.trainable = flag\n",
    "    for l in network.layers:\n",
    "        l.trainable = flag\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "inputs_b = Input(shape=(X_train.shape[1],))\n",
    "inputs_s = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "with K.name_scope('Classifier'):\n",
    "    Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "    Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "    Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "    Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "    D = Model(input=[inputs], output=[Dx])\n",
    "\n",
    "#@TODO: Gradient reversal layer, and simul training\n",
    "#@TODO: loss on only the signal, we want that to be flat\n",
    "Rx = Dx\n",
    "with K.name_scope('Advers'):\n",
    "    Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "    Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "    Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "    #for i in range(20):\n",
    "    #    Rx = Dense(32, activation=\"tanh\")(Rx)\n",
    "    #Rx = Dense(1, activation=\"sigmoid\")(Rx) #try regression activations @TODO\n",
    "    Rx = Dense(1, activation=\"relu\")(Rx)\n",
    "    R = Model(input=[inputs], outputs=[Rx])\n",
    "#@TODO: loss only on background events, tanh activation, batch norm, drop out, see Andreas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "lam = 3.0 #10.0 # pivotal trade-off\n",
    "\n",
    "def make_loss_D(c):\n",
    "    def loss_D(y_true, y_pred):\n",
    "        #return c * K.binary_crossentropy(y_true, y_pred)\n",
    "        return c * K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) #!!! new keras from 2.0.7\n",
    "    return loss_D\n",
    "\n",
    "def make_loss_R(c):\n",
    "    def loss_R(z_true, z_pred):\n",
    "        return c * mean_squared_error(z_true, z_pred) ##!!! new keras from 2.0.7\n",
    "    return loss_R\n",
    "\n",
    "#opt_D = SGD()\n",
    "opt_D = \"adam\"\n",
    "D.compile(loss=[make_loss_D(c=1.0)], optimizer=opt_D)\n",
    "#D.compile(loss=\"binary_crossentropy\", optimizer=opt_D)\n",
    "\n",
    "# Train D such that R loss (its c=-lam) is also minimised, make it invariant to R\n",
    "#can we train simultaneous? grad reversal layer???\n",
    "#opt_DRf = SGD(momentum=0.0)\n",
    "opt_DRf = \"adam\"\n",
    "DRf = Model(input=[inputs], output=[D(inputs), R(inputs)])\n",
    "# R only on signal\n",
    "#DRf = Model(input=[inputs_b, inputs_s], output=[D(inputs_b),D(inputs_s), R(inputs_s)])\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "# R only on signal\n",
    "#DRf.compile(loss=[make_loss_D(c=1.0),make_loss_D(c=1.0), make_loss_R(c=-lam)], optimizer=opt_DRf)\n",
    "DRf.compile(loss=[make_loss_D(c=1.0), make_loss_R(c=-lam)], optimizer=opt_DRf)\n",
    "#DRf.compile(loss=[\"binary_crossentropy\", \"mean_squared_error\"], loss_weights=[1,-lam], optimizer=opt_DRf)\n",
    "\n",
    "#opt_DfR = SGD(momentum=0.0)\n",
    "##opt_DfR = \"adam\" #!!!\n",
    "opt_DfR = SGD(lr=0.0000001)\n",
    "DfR = Model(input=[inputs], output=[R(inputs)])\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "#DfR.compile(loss=[make_loss_R(c=1.0)], optimizer=opt_DfR)\n",
    "DfR.compile(loss=[make_loss_R(c=lam)], optimizer=opt_DfR)\n",
    "#DfR.compile(loss=[\"mean_squared_error\"], loss_weights=[lam],optimizer=opt_DfR)\n",
    "#DfR.compile(loss=\"mean_squared_error\",optimizer=opt_DfR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard, TerminateOnNaN\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(\"D\"), write_images=True\n",
    "                          #, histogram_freq=1,write_grads=True\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pretrain D\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "##D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=15, callbacks=[tensorboard]) # 15 epochs\n",
    "D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=15, callbacks=[tensorboard],\n",
    "     validation_data=(X_train, y_train, weights_train)) # 15 epochs\n",
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10) # 10 epochs\n",
    "\n",
    "#D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train), len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretrain R\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "# Train with noly signal\n",
    "#DfR.fit(X_train[y_train==1], mass_train[y_train==1], sample_weight=weights_train[y_train==1], nb_epoch=5) # only signal\n",
    "#DfR.fit([X_train[y_train==1], X_train[y_train==1]], [mass_train[y_train==1],mass_train[y_train==1]], sample_weight=[weights_train[y_train==0],weights_train[y_train==1]], nb_epoch=5) # only signal\n",
    "# Train with noly signal, mask with weights=0\n",
    "DfR.fit(X_train, mass_train, sample_weight=weights_train*y_train, \n",
    "        callbacks=[tensorboard],\n",
    "        validation_data=(X_train, mass_train, weights_train*y_train), \n",
    "        nb_epoch=1000 )##15)#5)\n",
    "##DfR.fit(X_train, mass_train, sample_weight=weights_train*y_train, nb_epoch=1000)##15)#5)\n",
    "#DfR.fit(X_train, mass_train, sample_weight=weights_train, nb_epoch=5)\n",
    "\n",
    "#DfR.fit(X_train, mass_train, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import adam\n",
    "#DfR.compile(loss=[make_loss_R(c=lam)], optimizer=\"SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DfR.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DfR.evaluate(X_test, [mass_test], sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) #/ lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_r$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f - \\lambda L_r$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 128\n",
    "training_iterations = 50#201\n",
    "for i in range(training_iterations):\n",
    "    l = DRf.evaluate(X_test, [y_test, mass_test], sample_weight=[weights_test,weights_test], verbose=0)\n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    losses[\"L_f\"].append(l[1][None][0]) # why none, 0? just do l[1]??\n",
    "    losses[\"L_r\"].append(-l[2][None][0])\n",
    "    print(losses[\"L_f\"][-1], losses[\"L_r\"][-1] / lam, losses[\"L_r\"][-1])\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit D\n",
    "    make_trainable(R, False)\n",
    "    make_trainable(D, True)\n",
    "    indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "    print \"DRf\"\n",
    "    DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], sample_weight=[weights_train[indices], weights_train[indices]])\n",
    "        \n",
    "    # Fit R\n",
    "    make_trainable(R, True)\n",
    "    make_trainable(D, False)\n",
    "    print \"DfR\"\n",
    "    DfR.fit(X_train, mass_train, batch_size=batch_size, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, batch_size=batch_size, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #@TODO: try grad reversal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_dc = D.predict(X_test)\n",
    "y_pred_dc = y_pred_dc.ravel()\n",
    "roc_auc_score(y_test, y_pred_dc, sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(y_pred_dc[mass_test<mass_test.mean()], weights=weights_test[mass_test<mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred_dc[mass_test>=mass_test.mean()], weights=weights_test[mass_test>=mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred_dc)\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_predict = R.predict(X_test)\n",
    "mass_predict_train = R.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"mean true\",(mass_test[y_test==1]).mean(), \"mean pred\", np.mean(mass_predict[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"median true\",(mass_test[y_test==1]).median(), \"median pred\", np.median(mass_predict[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"std true\",(mass_test[y_test==1]).std(), \"std pred\", np.std(mass_predict[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Train: mean true\",(mass_train[y_train==1]).mean(), \"mean pred\", np.mean(mass_predict_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Train: median true\",(mass_train[y_train==1]).median(), \"median pred\", np.median(mass_predict_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Train: std true\",(mass_train[y_train==1]).std(), \"std pred\", np.std(mass_predict_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DfR.evaluate(X_test, [mass_test], sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mass_predict, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_test, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#doesnt change after adversrial training.. should get worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mass_predict[y_test==1], weights=weights_test[y_test==1], bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_test[y_test==1], weights=weights_test[y_test==1], bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(plt.titlelt.title(\"VBF Events\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mass_predict_train[y_train==1], weights=weights_train[y_train==1], bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_train[y_train==1], weights=weights_train[y_train==1], bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(plt.titlelt.title(\"VBF Events\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why cant it memorise? are there identical events? need to pca and project to 3d then see\n",
    "# mass comparison.. maybe binned regression is better with tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc_train = D.predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_pred_test_sig = [weights_train[(y_train ==1) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "#int_pred_test_bkg = [weights_train[(y_train ==0) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "\n",
    "int_pred_dc_test_sig = [weights_test[(y_test ==1) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_dc_test_bkg = [weights_test[(y_test ==0) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_sig)\n",
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import amsasimov\n",
    "vamsasimov_dc = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_dc_test_sig,int_pred_dc_test_bkg)]\n",
    "significance_dc = max(vamsasimov_dc)\n",
    "threshold_dc = np.linspace(0,1,num=50)[ np.array(vamsasimov_dc).argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_dc, threshold_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),vamsasimov_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import compare_train_test\n",
    "compare_train_test(y_pred_dc_train, y_train, y_pred_dc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGevMass(mass):\n",
    "    return np.exp (mass * (mass_max - mass_min) + mass_min)\n",
    "plt.hist(getGevMass(mass_test), weights=weights_test, bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score > \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Mass Distribution (s+b)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = np.zeros((len(mass_test),), dtype=[('mass',np.float64),('weight',np.float64),('NN_score',np.float64) ])\n",
    "temp['mass'] = np.array(getGevMass(mass_test))\n",
    "temp['weight'] = np.array(weights_test)\n",
    "temp['NN_score'] = np.array(y_pred_dc)\n",
    "\n",
    "from root_numpy import array2tree\n",
    "tree_dc = array2tree(temp)\n",
    "\n",
    "from ROOT import TEfficiency, TH1F\n",
    "bins = 50\n",
    "scoremin = temp['mass'].min()\n",
    "scoremax = temp['mass'].max()\n",
    "hpreselect_dc = TH1F(\"hpreselect_dc\", \"mass distribution before NN\", bins, scoremin, scoremax)\n",
    "hpreselect_dc.Sumw2()\n",
    "hD = TH1F(\"hD\", \"mass distribution for D Score > \" + str(threshold_dc), bins, scoremin, scoremax)\n",
    "hD.Sumw2()\n",
    "#tree.Project(\"hpreselect\", \"mass\", \"weight\" ) #Tefficiency can;t do weights\n",
    "tree_dc.Project(\"hpreselect_dc\", \"mass\" )\n",
    "#tree.Project(\"hNN\", \"mass\", \"weight*(NN_score>=\" +str(threshold) + \")\" )\n",
    "tree_dc.Project(\"hD\", \"mass\", \"(NN_score>=\" +str(threshold_dc) + \")\" )\n",
    "\n",
    "print TEfficiency.CheckConsistency(hD, hpreselect_dc)\n",
    "pEff_dc = TEfficiency(hD, hpreselect_dc)\n",
    "\n",
    "from ROOT import TCanvas\n",
    "c_dc = TCanvas(\"dcCanvas\",\"dc Canvas\",800,350)\n",
    "pEff_dc.SetTitle(\"Efficiency: Pre-selection vs Post D Selection;Mass (GeV) ;#epsilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pEff_dc.Draw(\"AP\")\n",
    "#ROOT.enableJSVis()\n",
    "c_dc.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mass_predict !=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again with adverserial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) #/ lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$\\lambda L_r$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f - \\lambda L_r$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "training_iterations = 201 #50\n",
    "for i in range(training_iterations):\n",
    "    #l = DRf.evaluate(X_test, [y_test, mass_test], sample_weight=[weights_test,weights_test], verbose=0)  \n",
    "    l = DRf.evaluate(X_train, [y_train, mass_train], sample_weight=[weights_train,weights_train], verbose=0)  \n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    losses[\"L_f\"].append(l[1][None][0]) # why none, 0? just do l[1]??\n",
    "    losses[\"L_r\"].append(-l[2][None][0]) # the - cancels the - in loss -lam\n",
    "    print(losses[\"L_f\"][-1], losses[\"L_r\"][-1] / lam, losses[\"L_r\"][-1])\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit D\n",
    "    make_trainable(R, False)\n",
    "    make_trainable(D, True)\n",
    "    indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "    print \"DRf\"\n",
    "    #use iloc\n",
    "    ##DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], sample_weight=[weights_train[indices], weights_train[indices]])\n",
    "    DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], sample_weight=[weights_train[indices], weights_train[indices]*y_train[indices]])\n",
    "    #@TODO: Make explicite masking with weights, y_train mught become multiclass later\n",
    "    \n",
    "    # Fit R\n",
    "    make_trainable(R, True)\n",
    "    make_trainable(D, False)\n",
    "    print \"DfR\"\n",
    "    #masking background events\n",
    "    DfR.fit(X_train, mass_train, batch_size=batch_size, sample_weight=weights_train*y_train, nb_epoch=1, verbose=1)\n",
    "    ##DfR.fit(X_train, mass_train, batch_size=batch_size, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, batch_size=batch_size, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #@TODO: try grad reversal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_dc = D.predict(X_test)\n",
    "y_pred_dc = y_pred_dc.ravel()\n",
    "roc_auc_score(y_test, y_pred_dc, sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(y_pred_dc[mass_test<mass_test.mean()], weights=weights_test[mass_test<mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred_dc[mass_test>=mass_test.mean()], weights=weights_test[mass_test>=mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred_dc)\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_predict = R.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DfR.evaluate(X_test, [mass_test], sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mass_predict, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_test, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#doesnt change after adversrial training.. should get worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc_train = D.predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_pred_test_sig = [weights_train[(y_train ==1) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "#int_pred_test_bkg = [weights_train[(y_train ==0) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "\n",
    "int_pred_dc_test_sig = [weights_test[(y_test ==1) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_dc_test_bkg = [weights_test[(y_test ==0) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_sig)\n",
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import amsasimov\n",
    "vamsasimov_dc = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_dc_test_sig,int_pred_dc_test_bkg)]\n",
    "significance_dc = max(vamsasimov_dc)\n",
    "threshold_dc = np.linspace(0,1,num=50)[ np.array(vamsasimov_dc).argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_dc, threshold_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),vamsasimov_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import compare_train_test\n",
    "compare_train_test(y_pred_dc_train, y_train, y_pred_dc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGevMass(mass):\n",
    "    return np.exp (mass * (mass_max - mass_min) + mass_min)\n",
    "plt.hist(getGevMass(mass_test), weights=weights_test, bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Mass Distribution (s+b)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But R looks at all events, not just the ones with high score so it tries to \n",
    "#also predict the mass of background. It shouldnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test,y=y_pred_dc, weights=weights_test, bins=50, label=\"Preselection\")\n",
    "#plt.hist2d(x=getGevMass(mass_test),y=y_pred_dc, weights=weights_test, bins=50, normed=1, label=\"Preselection\")\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of all Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test[y_pred_dc >= threshold_dc],y=y_pred_dc[y_pred_dc >= threshold_dc], weights=weights_test[y_pred_dc >= threshold_dc], bins=50, label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of Score >= \" + str(threshold_dc)+\" Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test[y_test ==1],y=y_pred_dc[y_test ==1], weights=weights_test[y_test ==1], bins=50, label=\"True VBF Events\")\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of Score >= \" + str(threshold_dc)+\" Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test[y_pred_dc < threshold_dc],y=y_pred_dc[y_pred_dc < threshold_dc], weights=weights_test[y_pred_dc < threshold_dc], bins=50, label=\"Score < \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of Score < \" + str(threshold_dc)+\" Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros((len(mass_test),), dtype=[('mass',np.float64),('weight',np.float64),('NN_score',np.float64) ])\n",
    "temp['mass'] = np.array(getGevMass(mass_test))\n",
    "temp['weight'] = np.array(weights_test)\n",
    "temp['NN_score'] = np.array(y_pred_dc)\n",
    "\n",
    "from root_numpy import array2tree\n",
    "tree_dc = array2tree(temp)\n",
    "\n",
    "from ROOT import TEfficiency, TH1F\n",
    "bins = 50\n",
    "scoremin = temp['mass'].min()\n",
    "scoremax = temp['mass'].max()\n",
    "hpreselect_dc = TH1F(\"hpreselect_dc\", \"mass distribution before NN\", bins, scoremin, scoremax)\n",
    "hpreselect_dc.Sumw2()\n",
    "hD = TH1F(\"hD\", \"mass distribution for D Score > \" + str(threshold_dc), bins, scoremin, scoremax)\n",
    "hD.Sumw2()\n",
    "#tree.Project(\"hpreselect\", \"mass\", \"weight\" ) #Tefficiency can;t do weights\n",
    "tree_dc.Project(\"hpreselect_dc\", \"mass\" )\n",
    "#tree.Project(\"hNN\", \"mass\", \"weight*(NN_score>=\" +str(threshold) + \")\" )\n",
    "tree_dc.Project(\"hD\", \"mass\", \"(NN_score>=\" +str(threshold_dc) + \")\" )\n",
    "\n",
    "print TEfficiency.CheckConsistency(hD, hpreselect_dc)\n",
    "pEff_dc = TEfficiency(hD, hpreselect_dc)\n",
    "\n",
    "from ROOT import TCanvas\n",
    "c_dc = TCanvas(\"dcCanvas\",\"dc Canvas\",800,350)\n",
    "pEff_dc.SetTitle(\"Efficiency: Pre-selection vs Post D Selection;Mass (GeV) ;#epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEff_dc.Draw(\"AP\")\n",
    "#ROOT.enableJSVis()\n",
    "c_dc.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mass_predict !=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard : PCA and see if its impossible to even memorize mass, identical events diff mass\n",
    "# find out why nan if I use indices but not train_test_split [because .iloc, fix]\n",
    "# try to just make a NN map 1 to 2, 2 to 6, 3 to 9 memorise it\n",
    "\n",
    "#: inject mass correlation and see if R learns anything at all. Find the elephant\n",
    "# R is sometimes learning somtimes not.. why.. reproducible problem?\n",
    "# the D without adverserial training is asmost same as after adverserial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sometimes training R gives 0 for every event... why. not reproducible?\n",
    "# why is the loss look decreasing further on pivot training, its not actually cuz auc is worse\n",
    "#@TODO: Compare AUC/significance with qq, without qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Victor:\n",
    "# pivot not working well\n",
    "# V: Try to overfit on 100 samples: find elephant problems\n",
    "# regression activation, loss function?\n",
    "# V: Its okay trial and error | andreas did classification\n",
    "# loss of r is changing at a lower level, maybe subtract off the first loss?\n",
    "# V: maybe\n",
    "# grad reversal layer\n",
    "# V: simultaneous could be better\n",
    "# why is the loss look decreasing further on pivot training, its not actually cuz auc is worse\n",
    "# V: Maybe you need to let pre-training converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip2 install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ams loss function: celver way to impliment, if else wont work: like makeing soft cuts\n",
    "# how close to 0, how close to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "635px",
    "left": "0px",
    "right": "1070px",
    "top": "110px",
    "width": "128px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
