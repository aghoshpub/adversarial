{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load signal, backgound data\n",
    "vbf_events = pd.read_hdf(\"../MC_Prod_v12/vbf_events.hdf\", \"vbf\")\n",
    "ggf_events = pd.read_hdf(\"../MC_Prod_v12/ggF_events.hdf\", \"ggF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf_events[\"class\"] = 1\n",
    "ggf_events[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([vbf_events, ggf_events])\n",
    "#print data.isnull().values.any()\n",
    "#data.describe()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle the events\n",
    "target = data[\"class\"]\n",
    "mass = data[\"m4l_fsr\"]\n",
    "weights = data[\"weight_couplings\"]\n",
    "del data[\"class\"]\n",
    "del data[\"m4l_fsr\"]\n",
    "del data[\"weight_couplings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = mass.apply(np.log)\n",
    "mass_max, mass_min = mass.max(), mass.min()\n",
    "mass = (mass - mass_min)/(mass_max - mass_min) #!!! save max, min values to file\n",
    "#mass.describe()\n",
    "#plt.hist(mass)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    "    train_test_split(data, target, mass, weights, train_size=0.75)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "#@TODO: check other activations in Andreas, Gilles pivot\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "D.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train *=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(weights_train ==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10) #nan loss\n",
    "#D.fit(X_train, y_train, nb_epoch=10) #unweighted training !!! @TODO: weighted\n",
    "D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train)) #unweighted training !!! @TODO: weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = D.predict(X_test)\n",
    "y_pred = y_pred.ravel()\n",
    "roc_auc_score(y_true=y_test, y_score=y_pred, sample_weight=weights_test)\n",
    "#roc_auc_score(y_true=y_test, y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_pred[mass_test<mass.mean()], weights=weights_test[mass_test<mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[mass_test>=mass.mean()], weights=weights_test[mass_test>=mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "#plt.hist(y_pred[mass_test<mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "#plt.hist(y_pred[mass_test>=mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "\n",
    "plt.ylim(0, 30)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred.ravel())\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_pred>0.5).sum()/float(y_pred.shape[0]) # much better than without class_weight training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "def make_trainable(network, flag):\n",
    "    network.trainable = flag\n",
    "    for l in network.layers:\n",
    "        l.trainable = flag\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "\n",
    "#@TODO: Gradient reversal layer, and simul training\n",
    "Rx = Dx\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(1, activation=\"sigmoid\")(Rx) #try regression activations\n",
    "R = Model(input=[inputs], outputs=[Rx])\n",
    "#@TODO: loss only on background events, tanh activation, batch norm, drop out, see Andreas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "lam = 10.0 # pivotal trade-off\n",
    "\n",
    "def make_loss_D(c):\n",
    "    def loss_D(y_true, y_pred):\n",
    "        return c * K.binary_crossentropy(y_pred, y_true)\n",
    "    return loss_D\n",
    "\n",
    "def make_loss_R(c):\n",
    "    def loss_R(z_true, z_pred):\n",
    "        return c * mean_squared_error(z_pred, z_true)\n",
    "    return loss_R\n",
    "\n",
    "opt_D = SGD()\n",
    "D.compile(loss=[make_loss_D(c=1.0)], optimizer=opt_D)\n",
    "\n",
    "# Train D such that R loss (its c=-lam) is also minimised, make it invariant to R\n",
    "#can we train simultaneous? grad reversal layer???\n",
    "opt_DRf = SGD(momentum=0.0)\n",
    "DRf = Model(input=[inputs], output=[D(inputs), R(inputs)])\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "DRf.compile(loss=[make_loss_D(c=1.0), make_loss_R(c=-lam)], optimizer=opt_DRf)\n",
    "\n",
    "opt_DfR = SGD(momentum=0.0)\n",
    "DfR = Model(input=[inputs], output=[R(inputs)])\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "DfR.compile(loss=[make_loss_R(c=1.0)], optimizer=opt_DfR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72115/72115 [==============================] - 3s - loss: 5.8049     \n",
      "Epoch 2/10\n",
      "72115/72115 [==============================] - 2s - loss: 5.5897     \n",
      "Epoch 3/10\n",
      "72115/72115 [==============================] - 3s - loss: 5.5229     \n",
      "Epoch 4/10\n",
      "72115/72115 [==============================] - 3s - loss: 5.5401     \n",
      "Epoch 5/10\n",
      "72115/72115 [==============================] - 3s - loss: 5.5614     \n",
      "Epoch 6/10\n",
      "72115/72115 [==============================] - 3s - loss: 5.5506     \n",
      "Epoch 7/10\n",
      "72115/72115 [==============================] - 2s - loss: 5.5587     \n",
      "Epoch 8/10\n",
      "72115/72115 [==============================] - 2s - loss: 5.4554     \n",
      "Epoch 9/10\n",
      "72115/72115 [==============================] - 2s - loss: 5.5061     \n",
      "Epoch 10/10\n",
      "72115/72115 [==============================] - 2s - loss: 5.5115     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x117cda850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain D\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "D.fit(X_train, y_train, nb_epoch=8, class_weight=get_class_weights(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0309     \n",
      "Epoch 2/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0207     \n",
      "Epoch 3/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0204     \n",
      "Epoch 4/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0203     \n",
      "Epoch 5/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0202     \n",
      "Epoch 6/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0201     \n",
      "Epoch 7/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0201     \n",
      "Epoch 8/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0201     \n",
      "Epoch 9/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0201     \n",
      "Epoch 10/10\n",
      "72115/72115 [==============================] - 3s - loss: 0.0201     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116c61390>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain R\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "DfR.fit(X_train, mass_train, nb_epoch=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) / lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_r$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f - \\lambda L_r$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1180e94d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAG6JJREFUeJzt3X+Q3HWd5/HnizBmgMwNMIExOpge\nwQtCciTLnG5qqWKCBKKWEMTdkqutsHuy+UOiGyluE4urHCIWwq2SsrSUlNFCCwnKFns5kbWCMrW6\nVUQnOGQmhphfcmkkSxiQy4SbGLPv+6M/YTuTTqanu7/d05nXo6prvv39fr7f7/udqcprvt9v9/er\niMDMzOyMRhdgZmaTgwPBzMwAB4KZmSUOBDMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzwIFgZmbJmY0u\nYCJmzpwZuVyu0WVMyKFDhzjnnHMaXUZdueepwT03jy1btrwaEReMN66pAiGXy9Hf39/oMiakr6+P\n3t7eRpdRV+55anDPzUPSi+WM8ykjMzMDHAhmZpY4EMzMDGiyawhmZvVw5MgR8vk8o6Ojx81vb29n\n+/btDapqfK2trXR1ddHS0lLR+g4EM7Mx8vk8bW1t5HI5JL01/+DBg7S1tTWwspOLCIaHh8nn83R3\nd1e0DZ8yMjMbY3R0lI6OjuPCYLKTREdHxwlHNRPhQDAzK6GZwuCYamt2IJiZGeBAMDOzxIFgZjZJ\nPfTQQ9x+++11258DwcxskhocHGTevHl1258Dwcxsktq6dasDwczMYGhoiLlz59Ztf/5impnZKaxc\nCQMDhemjR89i2rTqtzl/Pqxde+ox+/bto62tjfb29uPm33fffQwPD3Pbbbdx6aWXVl9MER8hmJlN\nQqWuH2zevJlHH32UXC5X8zAAHyGYmZ1S8V/yBw/+v7rduqLU9YM5c+Zw9dVXs2LFikz26SMEM7NJ\naHBwkHXr1pHL5cjlcixcuJCBgQGuuOKKzPbpIwQzs0nokUceOWHe2rVrueqqqzLbpwPBzKxJrFy5\nMtPt+5SRmZkBGQWCpFZJv5D0vKRtkj53knF/IenXacz3sqjFzMzKk9Upo8PANRExIqkF+LmkpyLi\n2WMDJL0H+CzwZxHxuqQLM6rFzMzKkEkgREQAI+ltS3rFmGF/A3wtIl5P67ySRS1mZlYeFf7vzmDD\n0jRgC3AJhf/4V41Z/o/Ab4A/A6YBd0fEP5XYznJgOUBnZ+eVGzZsyKTerIyMjDBjxoxGl1FX7nlq\nOJ17bm9v5+KLLz7hgTNHjx5lWi2+qpyRiGD37t288cYbx81ftGjRlojoGW/9zALhrR1I5wJPAJ+K\niKGi+T8EjgB/AXQB/wzMi4jfn2xbPT090d/fn2m9tdbX10dvb2+jy6gr9zw1nM497927l7a2thMe\no9kMz1Q+ePDgCc9UllRWIGT+sdOI+L2kZ4AlwFDRojywOSKOAHsl/QZ4D/DLrGsyMzuVrq4u8vk8\nBw4cOG7+6Ogora2tDapqfK2trXR1dVW8fiaBIOkC4EgKg7OAxcD9Y4b9I3AL8G1JM4H/COzJoh4z\ns4loaWk54a9sKBwVLViwoAEV1UdWRwizgIfTdYQzgO9HxA8l3QP0R8RG4MfAdZJ+DRwF/ltEDGdU\nj5mZjSOrTxltBU6I0YhYUzQdwB3pZWZmDeZvKpuZGeBAMDOzxIFgZmaAA8HMzBIHgpmZAQ4EMzNL\nHAhmZgY4EMzMLHEgmJkZ4EAwM7PEgWBmZoADwczMEgeCmZkBDgQzM0scCGZmBjgQzMwscSCYmRng\nQDAzs8SBYGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGZBQIklol/ULS85K2SfrcKcbeLCkk9WRRi5mZ\nlefMjLZ7GLgmIkYktQA/l/RURDxbPEhSG/C3wOaM6jAzszJlcoQQBSPpbUt6RYmhnwfuB0azqMPM\nzMqX2TUESdMkDQCvAJsiYvOY5X8CXBQRT2ZVg5mZlU8Rpf5wr+EOpHOBJ4BPRcRQmncG8FPgryLi\nt5L6gDsjor/E+suB5QCdnZ1XbtiwIdN6a21kZIQZM2Y0uoy6cs9Tg3tuHosWLdoSEeNep808EAAk\nrQHejIi/T+/bgd3AsdNKbwdeA24oFQrH9PT0RH//SRdPSn19ffT29ja6jLpyz1ODe24eksoKhKw+\nZXRBOjJA0lnAYuCFY8sj4o2ImBkRuYjIAc8yThiYmVm2srqGMAt4RtJW4JcUriH8UNI9km7IaJ9m\nZlaFTD52GhFbgQUl5q85yfjeLOowM7Py+ZvKZmYG1Omicq1IOgC82Og6Jmgm8Gqji6gz9zw1uOfm\nMTsiLhhvUFMFQjOS1F/O1f3TiXueGtzz6cenjMzMDHAgmJlZ4kDI3rpGF9AA7nlqcM+nGV9DMDMz\nwEcIZmaWOBDMzAxwINSEpPMlbZK0M/087yTjbk1jdkq6tcTyjZKGsq+4etX0LOlsSU9KeiE9Ue+L\n9a1+YiQtkbRD0i5Jq0ssny7psbR8s6Rc0bLPpvk7JF1fz7qrUWnPkhZL2iJpMP28pt61V6Ka33Fa\n/i5JI5LurFfNmYgIv6p8AQ8Aq9P0auD+EmPOB/akn+el6fOKln8U+B4w1Oh+su4ZOBtYlMa8DfgZ\n8MFG93SSPqdRuDPvu1OtzwOXjRnzSeAbafrjwGNp+rI0fjrQnbYzrdE9ZdzzAuAdaXou8FKj+8my\n36LljwM/oHAb/4b3VOnLRwi1cSPwcJp+GFhaYsz1FG7y91pEvA5sApYASJoB3AHcW4daa6XiniPi\nzYh4BiAi/gA8B3TVoeZKvA/YFRF7Uq0bKPRerPjf4nHgA5KU5m+IiMMRsRfYlbY32VXcc0T8KiJ+\nl+ZvA86SNL0uVVeumt8xkpYCeyn029QcCLXRGREvp+n9QGeJMe8E9hW9z6d5UHiU6JeANzOrsPaq\n7Rl46wFKHwF+kkWRNTBuD8VjIuKPwBtAR5nrTkbV9FzsZuC5iDicUZ21UnG/6Y+5VcDn6lBn5jK5\n2+npSNLTFB7kM9ZdxW8iIiSV/VleSfOBiyPiM2PPSzZaVj0Xbf9M4FHgKxGxp7IqbTKSdDmF56Vf\n1+haMnY38GBEjKQDhqbWVN9DmDlzZuRyuUaXMSGHDh3inHPOaXQZdeWepwb33Dy2bNnyapRxc7um\nOkLI5XL4EZqTn3ueGtxz85BU1l2ifQ3BzMwAB4KZmSUOBDMzA5rsGoKZWT0cOXKEfD7P6OjocfPb\n29vZvn17g6oaX2trK11dXbS0tFS0vgPBzGyMfD5PW1sbuVyO4o+THjx4kLa2tgZWdnIRwfDwMPl8\nnu7u7oq24VNGZmZjjI6O0tHRQTN9t0ASHR0dJxzVTERZgZDFja4kfUHSPkkjFVdvZpaRZgqDY6qt\nedxAkDQN+BrwQQo367pF0mVjhn0CeD0iLgEepPANRYBXgY9ExDzgVuC7Rev8b5rjvi5mZlNCOUcI\nmdzoKiKeLboXjpmZNVg5F5VL3fjp/ScbExF/lHTsRlevFo2p6EZXkpYDywE6Ozvp6+ubyOoNNzIy\n0nQ1V8s9Tw2nc8/t7e0cPHjwhPlHjx4tOT8r3/rWtxgaGuLLX/5y2euMjo5W/Hupy6eMqrnRVUSs\nIz3YuqenJ5rta+PN+lX3arjnqeF07nn79u0lP01U708Z7dy5kyuvvHJC+2xtbWXBggUV7a+cU0Yv\nARcVve9K80qOSXewbAeG0/su4AlgWUTsrqhKM7MpaOvWrcybN69u+ysnEH4JvEdSt6S3UXha0MYx\nYzZSuGgM8DHgp+mWyOcCT1J4sta/1KpoM7OpYGhoiLlz59Ztf+OeMkrXBFYAP6bwqLlvRcQ2SfcA\n/RGxEVgPfFfSLuA1CqEBsAK4BFgjaU2ad11EvCLpAeC/AGdLygPfjIi7a9mcmVm1Vv7TSgb2DwCF\nawjTpk2repvz3z6ftUvWnnLMvn37aGtro729veTyiKj5R2PLuoYQET8CfjRm3pqi6VHgz0usdy8n\neSxkRPwd8HcTKdbMbKoYHBw84XTR/v37uemmm1i6dCnLli1j1qxZNd2nb11hZnYKxX/J1/Oicqnr\nBwMDA9xyyy18+tOfzmSfvnWFmdkkNDg4yLp168jlcuRyORYuXMjAwACLFy/ObJ8+QjAzm4QeeeSR\nE+Z94hOfYM6cOZnt04FgZtYk1q9fn+n2fcrIzMwAB4KZmSUOBDMzAxwIZmaWOBDMzEqIiEaXMGHV\n1uxAMDMbo7W1leHh4aYKhWPPVG5tba14G/7YqZnZGF1dXeTzeQ4cOHDc/NHR0ar+w81aa2srXV1d\nFa/vQDAzG6OlpYXu7u4T5vf19VX8rIFm4FNGZmYGOBDMzCxxIJiZGeBAMDOzxIFgZmaAA8HMzBIH\ngpmZAWUGgqQlknZI2iVpdYnl0yU9lpZvlpRL8xdL2iJpMP28pmidK9P8XZK+olo/LdrMzCZk3ECQ\nNA34GvBB4DLgFkmXjRn2CeD1iLgEeBC4P81/FfhIRMwDbgW+W7TO14G/Ad6TXkuq6MPMzKpUzhHC\n+4BdEbEnIv4AbABuHDPmRuDhNP048AFJiohfRcTv0vxtwFnpaGIW8B8i4tko3CzkO8DSqrsxM7OK\nlRMI7wT2Fb3Pp3klx0TEH4E3gI4xY24GnouIw2l8fpxtmplZHdXlXkaSLqdwGum6CtZdDiwH6Ozs\npK+vr7bFZWxkZKTpaq6We54a3PPpp5xAeAm4qOh9V5pXakxe0plAOzAMIKkLeAJYFhG7i8YX35Kv\n1DYBiIh1wDqAnp6e6O3tLaPkyaOvr49mq7la7nlqcM+nn3JOGf0SeI+kbklvAz4ObBwzZiOFi8YA\nHwN+GhEh6VzgSWB1RPzLscER8TLwfyX9afp00TLgf1XZi5mZVWHcQEjXBFYAPwa2A9+PiG2S7pF0\nQxq2HuiQtAu4Azj20dQVwCXAGkkD6XVhWvZJ4JvALmA38FStmjIzs4kr6xpCRPwI+NGYeWuKpkeB\nPy+x3r3AvSfZZj8wdyLFmplZdvxNZTMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzwIFgZmaJA8HMzAAH\ngpmZJQ4EMzMDHAhmZpY4EMzMDHAgmJlZ4kAwMzPAgWBmZokDwczMAAeCmZklDgQzMwMcCGZmljgQ\nzMwMAEVEo2som6QDwIuNrmOCZgKvNrqIOnPPU4N7bh6zI+KC8QY1VSA0I0n9EdHT6DrqyT1PDe75\n9ONTRmZmBjgQzMwscSBkb12jC2gA9zw1uOfTjK8hmJkZ4CMEMzNLHAg1IOl8SZsk7Uw/zzvJuFvT\nmJ2Sbi2xfKOkoewrrl41PUs6W9KTkl6QtE3SF+tb/cRIWiJph6RdklaXWD5d0mNp+WZJuaJln03z\nd0i6vp51V6PSniUtlrRF0mD6eU29a69ENb/jtPxdkkYk3VmvmjMREX5V+QIeAFan6dXA/SXGnA/s\nST/PS9PnFS3/KPA9YKjR/WTdM3A2sCiNeRvwM+CDje7pJH1OA3YD7061Pg9cNmbMJ4FvpOmPA4+l\n6cvS+OlAd9rOtEb3lHHPC4B3pOm5wEuN7ifLfouWPw78ALiz0f1U8/IRQm3cCDycph8GlpYYcz2w\nKSJei4jXgU3AEgBJM4A7gHvrUGutVNxzRLwZEc8ARMQfgOeArjrUXIn3AbsiYk+qdQOF3osV/1s8\nDnxAktL8DRFxOCL2ArvS9ia7inuOiF9FxO/S/G3AWZKm16XqylXzO0bSUmAvhX6bmgOhNjoj4uU0\nvR/oLDHmncC+ovf5NA/g88CXgDczq7D2qu0ZAEnnAh8BfpJFkTUwbg/FYyLij8AbQEeZ605G1fRc\n7GbguYg4nFGdtVJxv+mPuVXA5+pQZ+bObHQBzULS08DbSyy6q/hNRISksj+6JWk+cHFEfGbseclG\ny6rnou2fCTwKfCUi9lRWpU1Gki4H7geua3QtGbsbeDAiRtIBQ1NzIJQpIq492TJJ/yppVkS8LGkW\n8EqJYS8BvUXvu4A+YCHQI+m3FH4fF0rqi4heGizDno9ZB+yMiLU1KDcrLwEXFb3vSvNKjcmnkGsH\nhstcdzKqpmckdQFPAMsiYnf25Vatmn7fD3xM0gPAucC/SRqNiK9mX3btNdX3EGbOnBm5XK7RZUzI\noUOHOOeccxpdRl2556nBPTePLVu2vBpl3NyuqY4Qcrkc/f39jS5jQvr6+ujt7W10GXXlnqcG99w8\nJJV1l2hfVDYzM8CBYGZmiQPBzMyAJruGYGZT15EjR8jn84yOjjashvb2drZv396w/Y+ntbWVrq4u\nWlpaKlrfgWBmTSGfz9PW1kYul6NRn/k/ePAgbW1tDdn3eCKC4eFh8vk83d3dFW3Dp4zMrCmMjo7S\n0dHRsDCY7CTR0dFR1RGUA8HMmobD4NSq/fdxIJiZGeBAMDOzxIFgZjYBDz30ELfffnvNtjc4OMjs\n2bP5+te/nul+yuFAMDObgMHBQebNm1ez7c2bN48NGzbwne98J9P9lMOBYGY2AVu3bq35f9QXXngh\n27Yd/3ydLPYzHn8Pwcyaz8qVMDBQ223Onw9rx78T+9DQEHPnzq3prlevXs3hw4d58cUXmT17dmb7\nGY8DwcysTMe+HNfe3n7c/Pvuu4/h4WFuu+02Lr30UgCuvfZa9u/ff8I2vvCFL3Djjf/+hM6nnnqK\nQ4cO8eEPf5ht27Yxe/Zs9u3bV3I/xSKi5h/DdSCYWfMp4y/5LGzbtu2E0zibN2/m0UcfZfny5W+F\nAcDTTz897vZGR0dZtWoVGzdu5Nvf/jZDQ0N86EMfOun1g/3793PTTTexdOlSli1bxqxZs6pvqoiv\nIZiZlalUIMyZM4err76aFStWTHh79957L8uWLSOXyzFv3jyGhoaAk18/GBgY4JZbbmHVqlU1DwNw\nIJiZlW3btm2sW7eOXC5HLpdj4cKFDAwMcMUVV0x4Wzt27GDTpk2sXLkS4LhAGBwcPGE/UAiExYsX\n166hMXzKyMysTOvXrz/h5nZr167lqquumvC25syZw+bNm497/9xzzwHwyCOPlFxn586dzJkzZ8L7\nKlcmgSCpFfhnYHrax+MR8T9OMvZm4HHgP0dEcz0f08ymvGN/4dfD+vXrM91+VkcIh4FrImJEUgvw\nc0lPRcSzxYMktQF/C2wutREzM6ufTK4hRMFIetuSXlFi6OeB+4HGPfHCzMyADC8qS5omaQB4BdgU\nEZvHLP8T4KKIeDKrGszMrHyZXVSOiKPAfEnnAk9ImhsRQwCSzgC+DPzVeNuRtBxYDtDZ2UlfX19W\nJWdiZGSk6WqulnueGurdc3t7OwcPHqzb/ko5evRow2sYz+joaMW/F0WUOpNTW5LWAG9GxN+n9+3A\nbuDYaaW3A68BN5zqwnJPT0/09zfXdee+vj56e3sbXUZdueepod49b9++nUsvvbShD8mZzI/QhMK3\nl1944QXe+973Hjdf0paI6Blv/UxOGUm6IB0ZIOksYDHwwrHlEfFGRMyMiFxE5IBnGScMzGxqa21t\nZXh4mHr8EduMjj1TubW1teJtZHXKaBbwsKRpFELn+xHxQ0n3AP0RsTGj/ZrZaaqrq4t8Ps+BAwca\nVsPo6GhV/+FmrbW1la6urorXzyQQImIrsKDE/DUnGd+bRR1mdvpoaWmhu7u7oTX09fWxYMEJ/7Wd\nNnzrCjMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzwIFgZmaJA8HMzAAHgpmZJQ4EMzMDHAhmZpY4EMzM\nDHAgmJlZ4kAwMzPAgWBmZokDwczMAAeCmZklDgQzMwMcCGZmljgQzMwMcCCYmVniQDAzM8CBYGZm\niQPBzMwAB4KZmSUOBDMzAxwIZmaWZBIIklol/ULS85K2SfpciTF3SPq1pK2SfiJpdha1mJlZebI6\nQjgMXBMRVwDzgSWS/nTMmF8BPRHxn4DHgQcyqsXMzMqQSSBEwUh625JeMWbMMxHxZnr7LNCVRS1m\nZlYeRcT4oyrZsDQN2AJcAnwtIladYuxXgf0RcW+JZcuB5QCdnZ1XbtiwIZN6szIyMsKMGTMaXUZd\nueepwT03j0WLFm2JiJ7xxmUWCG/tQDoXeAL4VEQMlVj+l8AK4OqIOHyqbfX09ER/f382hWakr6+P\n3t7eRpdRV+55anDPzUNSWYGQ+aeMIuL3wDPAkrHLJF0L3AXcMF4YmJlZtrL6lNEF6cgASWcBi4EX\nxoxZADxEIQxeyaIOMzMr35kZbXcW8HC6jnAG8P2I+KGke4D+iNgI/E9gBvADSQD/JyJuyKgeMzMb\nRyaBEBFbgQUl5q8pmr42i32bmVllMr+oXEuSDgAvNrqOCZoJvNroIurMPU8N7rl5zI6IC8Yb1FSB\n0Iwk9Zdzdf904p6nBvd8+vG9jMzMDHAgmJlZ4kDI3rpGF9AA7nlqcM+nGV9DMDMzwEcIZmaWOBBq\nQNL5kjZJ2pl+nneScbemMTsl3Vpi+UZJJ9zvaTKqpmdJZ0t6UtIL6XkZX6xv9RMjaYmkHZJ2SVpd\nYvl0SY+l5Zsl5YqWfTbN3yHp+nrWXY1Ke5a0WNIWSYPp5zX1rr0S1fyO0/J3SRqRdGe9as5ERPhV\n5YvCsxxWp+nVwP0lxpwP7Ek/z0vT5xUt/yjwPWCo0f1k3TNwNrAojXkb8DPgg43u6SR9TgN2A+9O\ntT4PXDZmzCeBb6TpjwOPpenL0vjpQHfazrRG95RxzwuAd6TpucBLje4ny36Llj8O/AC4s9H9VPPy\nEUJt3Ag8nKYfBpaWGHM9sCkiXouI14FNpBv+SZoB3AGccPvvSaziniPizYh4BiAi/gA8x+R9Hsb7\ngF0RsSfVuoFC78WK/y0eBz6gwv1YbgQ2RMThiNgL7Erbm+wq7jkifhURv0vztwFnSZpel6orV83v\nGElLgb0U+m1qDoTa6IyIl9P0fqCzxJh3AvuK3ufTPIDPA18C3hy70iRWbc/AW7dH/wjwkyyKrIFx\neygeExF/BN4AOspcdzKqpudiNwPPxeS/k3HF/aY/5lYBJzwmuBlldXO7046kp4G3l1h0V/GbiAhJ\nZX90S9J84OKI+MzY85KNllXPRds/E3gU+EpE7KmsSpuMJF0O3A9c1+haMnY38GBEjKQDhqbmQChT\nnOJmfJL+VdKsiHhZ0iyg1O28XwJ6i953AX3AQqBH0m8p/D4ulNQXEb00WIY9H7MO2BkRa2tQblZe\nAi4qet+V5pUak08h1w4Ml7nuZFRNz0jqovBQrGURsTv7cqtWTb/vBz4m6QHgXODfJI1GxFezLzsD\njb6IcTq8KNzKu/gC6wMlxpxP4Tzjeem1Fzh/zJgczXNRuaqeKVwv+QfgjEb3Mk6fZ1K4GN7Nv19w\nvHzMmNs5/oLj99P05Rx/UXkPzXFRuZqez03jP9roPurR75gxd9PkF5UbXsDp8KJw7vQnwE7g6aL/\n9HqAbxaN+68ULizuAv66xHaaKRAq7pnCX2ABbAcG0uu2Rvd0il4/BPyGwidR7krz7qHwcCeAVgqf\nMNkF/AJ4d9G6d6X1djBJP0lVy56B/w4cKvq9DgAXNrqfLH/HRdto+kDwN5XNzAzwp4zMzCxxIJiZ\nGeBAMDOzxIFgZmaAA8HMzBIHgpmZAQ4EMzNLHAhmZgbA/wfVeQA2MkvXHwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1180e94d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "11264/72115 [===>..........................] - ETA: 0s - loss: nan"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      " 4096/72115 [>.............................] - ETA: 0s - loss: nan"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for i in range(201):\n",
    "    l = DRf.evaluate(X_test, [y_test, mass_test], verbose=0) #add weight!!!   \n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    losses[\"L_f\"].append(l[1][None][0])\n",
    "    losses[\"L_r\"].append(-l[2][None][0])\n",
    "    print(losses[\"L_r\"][-1] / lam)\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit D\n",
    "    make_trainable(R, False)\n",
    "    make_trainable(D, True)\n",
    "    indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "    DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]])\n",
    "        \n",
    "    # Fit R\n",
    "    make_trainable(R, True)\n",
    "    make_trainable(D, False)\n",
    "    DfR.fit(X_train, mass_train, batch_size=batch_size, nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
