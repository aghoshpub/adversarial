{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load signal, backgound data\n",
    "vbf_events = pd.read_hdf(\"../MC_Prod_v12/vbf_events.hdf\", \"vbf\")\n",
    "ggf_events = pd.read_hdf(\"../MC_Prod_v12/ggF_events.hdf\", \"ggF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf_events[\"class\"] = 1\n",
    "ggf_events[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([vbf_events, ggf_events])\n",
    "#print data.isnull().values.any()\n",
    "#data.describe()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle the events\n",
    "target = data[\"class\"]\n",
    "mass = data[\"m4l_fsr\"]\n",
    "weights = data[\"weight_couplings\"]\n",
    "del data[\"class\"]\n",
    "del data[\"m4l_fsr\"]\n",
    "del data[\"weight_couplings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = mass.apply(np.log)\n",
    "mass_max, mass_min = mass.max(), mass.min()\n",
    "mass = (mass - mass_min)/(mass_max - mass_min) #!!! save max, min values to file\n",
    "#mass.describe()\n",
    "#plt.hist(mass)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dijet_invmass</th>\n",
       "      <th>dijet_deltaeta</th>\n",
       "      <th>eta_zepp_ZZ</th>\n",
       "      <th>min_dR_jZ</th>\n",
       "      <th>leading_jet_width</th>\n",
       "      <th>subleading_jet_width</th>\n",
       "      <th>jet_pt[0]</th>\n",
       "      <th>jet_pt[1]</th>\n",
       "      <th>max(50,pt4ljj_unconstrained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>676.015625</td>\n",
       "      <td>5.783263</td>\n",
       "      <td>3.361613</td>\n",
       "      <td>0.192956</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.159851</td>\n",
       "      <td>40.896393</td>\n",
       "      <td>34.541592</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1561.998657</td>\n",
       "      <td>4.440324</td>\n",
       "      <td>3.503239</td>\n",
       "      <td>0.348406</td>\n",
       "      <td>0.076004</td>\n",
       "      <td>0.035620</td>\n",
       "      <td>193.487579</td>\n",
       "      <td>145.230377</td>\n",
       "      <td>50.889210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691.180359</td>\n",
       "      <td>4.673340</td>\n",
       "      <td>0.244048</td>\n",
       "      <td>2.102819</td>\n",
       "      <td>0.159248</td>\n",
       "      <td>0.055365</td>\n",
       "      <td>69.184822</td>\n",
       "      <td>64.605484</td>\n",
       "      <td>102.805382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200.617050</td>\n",
       "      <td>1.997052</td>\n",
       "      <td>1.959151</td>\n",
       "      <td>1.149848</td>\n",
       "      <td>0.087246</td>\n",
       "      <td>0.124250</td>\n",
       "      <td>73.673546</td>\n",
       "      <td>58.334347</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>547.079834</td>\n",
       "      <td>3.255447</td>\n",
       "      <td>1.500816</td>\n",
       "      <td>2.345984</td>\n",
       "      <td>0.173809</td>\n",
       "      <td>0.092220</td>\n",
       "      <td>179.151917</td>\n",
       "      <td>59.333988</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dijet_invmass  dijet_deltaeta  eta_zepp_ZZ  min_dR_jZ  leading_jet_width  \\\n",
       "0     676.015625        5.783263     3.361613   0.192956           0.002567   \n",
       "1    1561.998657        4.440324     3.503239   0.348406           0.076004   \n",
       "2     691.180359        4.673340     0.244048   2.102819           0.159248   \n",
       "3     200.617050        1.997052     1.959151   1.149848           0.087246   \n",
       "4     547.079834        3.255447     1.500816   2.345984           0.173809   \n",
       "\n",
       "   subleading_jet_width   jet_pt[0]   jet_pt[1]  max(50,pt4ljj_unconstrained)  \n",
       "0              0.159851   40.896393   34.541592                     50.000000  \n",
       "1              0.035620  193.487579  145.230377                     50.889210  \n",
       "2              0.055365   69.184822   64.605484                    102.805382  \n",
       "3              0.124250   73.673546   58.334347                     50.000000  \n",
       "4              0.092220  179.151917   59.333988                     50.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    "    train_test_split(data, target, mass, weights, train_size=0.75)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "#@TODO: check other activations in Andreas, Gilles pivot\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "D.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train *=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(weights_train ==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7582     \n",
      "Epoch 2/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7312     \n",
      "Epoch 3/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7255     \n",
      "Epoch 4/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7227     \n",
      "Epoch 5/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7204     \n",
      "Epoch 6/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7188     \n",
      "Epoch 7/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7175     \n",
      "Epoch 8/10\n",
      "72115/72115 [==============================] - 4s - loss: 0.7161     \n",
      "Epoch 9/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7151     \n",
      "Epoch 10/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7144     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10e588510>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10) #nan loss\n",
    "#D.fit(X_train, y_train, nb_epoch=10) #unweighted training !!! @TODO: weighted\n",
    "D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train)) #unweighted training !!! @TODO: weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88610069756203247"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = D.predict(X_test)\n",
    "y_pred = y_pred.ravel()\n",
    "roc_auc_score(y_true=y_test, y_score=y_pred, sample_weight=weights_test)\n",
    "#roc_auc_score(y_true=y_test, y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    96154.000000\n",
       "mean         0.183742\n",
       "std          0.143495\n",
       "min          0.000000\n",
       "25%          0.070799\n",
       "50%          0.151313\n",
       "75%          0.264540\n",
       "max          1.000000\n",
       "Name: m4l_fsr, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11650f5d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred[mass_test<mass.mean()], weights=weights_test[mass_test<mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[mass_test>=mass.mean()], weights=weights_test[mass_test>=mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "#plt.hist(y_pred[mass_test<mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "#plt.hist(y_pred[mass_test>=mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "\n",
    "plt.ylim(0, 30)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted correlation with mass is (0.17303953, 6.2704448230309427e-161)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred.ravel())\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71583676525645823"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred>0.5).sum()/float(y_pred.shape[0]) # much better than without class_weight training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:20: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "def make_trainable(network, flag):\n",
    "    network.trainable = flag\n",
    "    for l in network.layers:\n",
    "        l.trainable = flag\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "\n",
    "#@TODO: Gradient reversal layer, and simul training\n",
    "Rx = Dx\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(1, activation=\"sigmoid\")(Rx) #try regression activations\n",
    "R = Model(input=[inputs], outputs=[Rx])\n",
    "#@TODO: loss only on background events, tanh activation, batch norm, drop out, see Andreas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:22: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "lam = 10.0 # pivotal trade-off\n",
    "\n",
    "def make_loss_D(c):\n",
    "    def loss_D(y_true, y_pred):\n",
    "        return c * K.binary_crossentropy(y_pred, y_true)\n",
    "    return loss_D\n",
    "\n",
    "def make_loss_R(c):\n",
    "    def loss_R(z_true, z_pred):\n",
    "        return c * mean_squared_error(z_pred, z_true)\n",
    "    return loss_R\n",
    "\n",
    "opt_D = SGD()\n",
    "D.compile(loss=[make_loss_D(c=1.0)], optimizer=opt_D)\n",
    "\n",
    "# Train D such that R loss (its c=-lam) is also minimised, make it invariant to R\n",
    "#can we train simultaneous? grad reversal layer???\n",
    "opt_DRf = SGD(momentum=0.0)\n",
    "DRf = Model(input=[inputs], output=[D(inputs), R(inputs)])\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "DRf.compile(loss=[make_loss_D(c=1.0), make_loss_R(c=-lam)], optimizer=opt_DRf)\n",
    "\n",
    "opt_DfR = SGD(momentum=0.0)\n",
    "DfR = Model(input=[inputs], output=[R(inputs)])\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "DfR.compile(loss=[make_loss_R(c=1.0)], optimizer=opt_DfR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "72115/72115 [==============================] - 3s - loss: 5.8536     \n",
      "Epoch 2/8\n",
      "72115/72115 [==============================] - 2s - loss: 5.5650     \n",
      "Epoch 3/8\n",
      "72115/72115 [==============================] - 2s - loss: 5.5408     \n",
      "Epoch 4/8\n",
      "72115/72115 [==============================] - 3s - loss: 5.5565     \n",
      "Epoch 5/8\n",
      "72115/72115 [==============================] - 3s - loss: 5.5867     \n",
      "Epoch 6/8\n",
      "72115/72115 [==============================] - 3s - loss: 5.5878     \n",
      "Epoch 7/8\n",
      "72115/72115 [==============================] - 2s - loss: 5.4964     \n",
      "Epoch 8/8\n",
      "72115/72115 [==============================] - 2s - loss: 5.4762     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1122388d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain D\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0282     \n",
      "Epoch 2/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0209     \n",
      "Epoch 3/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0204     \n",
      "Epoch 4/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0203     \n",
      "Epoch 5/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0202     \n",
      "Epoch 6/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0202     \n",
      "Epoch 7/7\n",
      "72115/72115 [==============================] - 3s - loss: 0.0202     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1219daa90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain R\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "DfR.fit(X_train, mass_train, nb_epoch=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) / lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_r$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f - \\lambda L_r$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122c0d690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x122c0d690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n",
      "nan\n",
      "Epoch 1/1\n",
      "72115/72115 [==============================] - 0s - loss: nan     \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0de62f2a4840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDRf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmass_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#add weight!!!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"L_f - L_r\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"L_f\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1655\u001b[0m                                \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1656\u001b[0m                                \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1657\u001b[0;31m                                steps=steps)\n\u001b[0m\u001b[1;32m   1658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1659\u001b[0m     def predict(self, x,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_test_loop\u001b[0;34m(self, f, ins, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1343\u001b[0m                             \u001b[0mouts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1344\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1345\u001b[0;31m                         \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_out\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1346\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "\n",
    "for i in range(201):\n",
    "    l = DRf.evaluate(X_test, [y_test, mass_test], verbose=0) #add weight!!!   \n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    losses[\"L_f\"].append(l[1][None][0])\n",
    "    losses[\"L_r\"].append(-l[2][None][0])\n",
    "    print(losses[\"L_r\"][-1] / lam)\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit D\n",
    "    make_trainable(R, False)\n",
    "    make_trainable(D, True)\n",
    "    indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "    DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], class_weight=get_class_weights(y_train[indices]))\n",
    "        \n",
    "    # Fit R\n",
    "    make_trainable(R, True)\n",
    "    make_trainable(D, False)\n",
    "    DfR.fit(X_train, mass_train, batch_size=batch_size, nb_epoch=1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
