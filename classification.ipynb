{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load signal, backgound data\n",
    "vbf_events = pd.read_hdf(\"../MC_Prod_v12/vbf_events.hdf\", \"vbf\") #do hdf5!!\n",
    "ggf_events = pd.read_hdf(\"../MC_Prod_v12/ggF_events.hdf\", \"ggF\")\n",
    "qq_events = pd.read_hdf(\"../MC_Prod_v12/qq_all_events.hdf\", \"qq_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf_events[\"class\"] = 1\n",
    "ggf_events[\"class\"] = 2 # need to reweight ggF better! set to 0 afterwards\n",
    "qq_events[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60.047187373963304, 6.0885523004705586, 8.7771621167023159)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "60.047187373963304"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights = qq_events.weight_couplings.sum(), vbf_events.weight_couplings.sum(), ggf_events.weight_couplings.sum()\n",
    "print class_weights\n",
    "max(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([vbf_events, ggf_events, qq_events])\n",
    "#data = pd.concat([vbf_events, ggf_events])\n",
    "#print data.isnull().values.any()\n",
    "#data.describe()\n",
    "\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle the events\n",
    "target = data[\"class\"]\n",
    "mass = data[\"m4l_fsr\"]\n",
    "weights = data[\"weight_couplings\"]\n",
    "del data[\"class\"]\n",
    "del data[\"m4l_fsr\"]\n",
    "del data[\"weight_couplings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass = mass.apply(np.log)\n",
    "mass_max, mass_min = mass.max(), mass.min()\n",
    "mass = (mass - mass_min)/(mass_max - mass_min) #!!! save max, min values to file\n",
    "#mass.describe()\n",
    "#plt.hist(mass)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Train-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reweight Events\n",
    "Training: 1000x everything, fraction 1/3 VBF 1/3 ggF 1/3 qq ~~0.5 VBF, 0.25 ggF, 0.25 qq~~\n",
    "\n",
    "Testing: Back to original VBF, ggF, qq sum of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_size = 0.01 #0.75 # 0.1 # !!!\n",
    "X_train, X_test, y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    "    train_test_split(data, target, mass, weights, train_size=train_size)\n",
    "#reset index for dataseries, not needed for ndarray (X_train, X_test)\n",
    "y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    " y_train.reset_index(drop=True),y_test.reset_index(drop=True), \\\n",
    "    mass_train.reset_index(drop=True), mass_test.reset_index(drop=True), \\\n",
    "    weights_train.reset_index(drop=True), weights_test.reset_index(drop=True)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "class_weights_test = weights_test[y_test == 0].sum(), weights_test[y_test == 1].sum(), weights_test[y_test == 2].sum()\n",
    "scale_up = 1000.\n",
    "for i in xrange(3):\n",
    "    weights_train[y_train == i] *= scale_up*max(class_weights)/ class_weights[i]\n",
    "    weights_test[y_test == i] *= class_weights[i]/class_weights_test[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(614.70299069308965, 600.63997904716473, 525.24272946231815)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_train[y_train == 0].sum(), weights_train[y_train == 1].sum(), weights_train[y_train == 2].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60.04718737396329, 6.0885523004705595, 8.7771621167023142)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_test[y_test == 0].sum(), weights_test[y_test == 1].sum(), weights_test[y_test == 2].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make ggF background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == 2] = 0\n",
    "y_test[y_test == 2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "#@TODO: check other activations in Andreas, Gilles pivot\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "D.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train *=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(weights_train ==0).any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10)\n",
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=1) #short for testing purposes\n",
    "#D.fit(X_train, y_train, nb_epoch=10) #unweighted training\n",
    "#D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train)) #Only interclass weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vbf_events), len(ggf_events), len(qq_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_test ==2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = D.predict(X_test)\n",
    "y_pred = y_pred.ravel()\n",
    "roc_auc_score(y_true=y_test, y_score=y_pred, sample_weight=weights_test)\n",
    "#roc_auc_score(y_true=y_test, y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = D.predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_pred_test_sig = [weights_train[(y_train ==1) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "#int_pred_test_bkg = [weights_train[(y_train ==0) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "\n",
    "int_pred_test_sig = [weights_test[(y_test ==1) & (y_pred > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_test_bkg = [weights_test[(y_test ==0) & (y_pred > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),int_pred_test_sig)\n",
    "plt.plot(np.linspace(0,1,num=50),int_pred_test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import amsasimov\n",
    "vamsasimov = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_test_sig,int_pred_test_bkg)]\n",
    "significance = max(vamsasimov)\n",
    "threshold = np.linspace(0,1,num=50)[ np.array(vamsasimov).argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance, threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),vamsasimov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import compare_train_test\n",
    "compare_train_test(y_pred_train, y_train, y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mass_test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(y_pred[mass_test<mass_test.mean()], weights=weights_test[mass_test<mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[mass_test>=mass_test.mean()], weights=weights_test[mass_test>=mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "#plt.hist(y_pred[mass_test<mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "#plt.hist(y_pred[mass_test>=mass.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "\n",
    "plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()# @TODO: do sep for signal background, plot mass : full mass dist, vs after cut on bdt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "signal_low = list (set( np.where(y_test==1)[0] ) & set( np.where(mass_test<mass_test.mean())[0]))\n",
    "signal_high = list (set( np.where(y_test==1)[0] ) & set( np.where(mass_test>=mass_test.mean())[0]))\n",
    "\n",
    "plt.hist(y_pred[signal_low], weights=weights_test[signal_low], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[signal_high], weights=weights_test[signal_high], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.title(\"Predicted scores for VBF events for low and high mass\")\n",
    "plt.ylim(0, 8)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bkg_low = list (set( np.where(y_test==0)[0] ) & set( np.where(mass_test<mass_test.mean())[0]))\n",
    "bkg_high = list (set( np.where(y_test==0)[0] ) & set( np.where(mass_test>=mass_test.mean())[0]))\n",
    "\n",
    "plt.hist(y_pred[bkg_low], weights=weights_test[bkg_low], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[bkg_high], weights=weights_test[bkg_high], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.title(\"Predicted scores for background events for low and high mass\")\n",
    "plt.ylim(0, 4)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGevMass(mass):\n",
    "    return np.exp (mass * (mass_max - mass_min) + mass_min)\n",
    "plt.hist(getGevMass(mass_test), weights=weights_test, bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[y_pred >= threshold]), weights=weights_test[y_pred >= threshold], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score > \" + str(threshold))\n",
    "\n",
    "plt.title(\"Mass Distribution (s+b)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros((len(mass_test),), dtype=[('mass',np.float64),('weight',np.float64),('NN_score',np.float64) ])\n",
    "temp['mass'] = np.array(getGevMass(mass_test))\n",
    "temp['weight'] = np.array(weights_test)\n",
    "temp['NN_score'] = np.array(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from root_numpy import array2tree\n",
    "tree = array2tree(temp)\n",
    "\n",
    "from ROOT import TEfficiency, TH1F\n",
    "bins = 50\n",
    "scoremin = temp['mass'].min()\n",
    "scoremax = temp['mass'].max()\n",
    "hpreselect = TH1F(\"hpreselect\", \"mass distribution before NN\", bins, scoremin, scoremax)\n",
    "hpreselect.Sumw2()\n",
    "hNN = TH1F(\"hNN\", \"mass distribution for NN Score > \" + str(threshold), bins, scoremin, scoremax)\n",
    "hNN.Sumw2()\n",
    "#tree.Project(\"hpreselect\", \"mass\", \"weight\" ) #Tefficiency can;t do weights\n",
    "tree.Project(\"hpreselect\", \"mass\" )\n",
    "#tree.Project(\"hNN\", \"mass\", \"weight*(NN_score>=\" +str(threshold) + \")\" )\n",
    "tree.Project(\"hNN\", \"mass\", \"(NN_score>=\" +str(threshold) + \")\" )\n",
    "\n",
    "print TEfficiency.CheckConsistency(hNN, hpreselect)\n",
    "pEff = TEfficiency(hNN, hpreselect)\n",
    "\n",
    "from ROOT import TCanvas\n",
    "c = TCanvas(\"myCanvasName\",\"The Canvas Title\",800,350)\n",
    "pEff.SetTitle(\"Efficiency: Pre-selection vs Post NN Selection;Mass (GeV) ;#epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEff.Draw(\"AP\")\n",
    "#ROOT.enableJSVis()\n",
    "c.Draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(getGevMass(mass_test[y_test==1]), weights=weights_test[y_test==1], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[(y_test==1) & (y_pred >= threshold)]), weights=weights_test[(y_test==1) & (y_pred >= threshold)], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(round(threshold,2)))\n",
    "\n",
    "plt.title(\"VBF Events\")\n",
    "plt.xlabel(\"Mass (GeV)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(220,800 )\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(getGevMass(mass_test[y_test==0]), weights=weights_test[y_test==0], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[(y_test==0) & (y_pred >= threshold)]), weights=weights_test[(y_test==0) & (y_pred >= threshold)], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(round(threshold,2)))\n",
    "\n",
    "plt.title(\"Background Like Events (qq, ggF)\")\n",
    "plt.xlim(220,800 )\n",
    "plt.xlabel(\"Mass (GeV)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred)\n",
    "print \"Unweighted correlation of all test events with mass is\", corr\n",
    "\n",
    "corr = pearsonr(mass_test[y_test ==1], y_pred[y_test ==1])\n",
    "print \"Unweighted correlation of signal test with mass is\", corr\n",
    "\n",
    "corr = pearsonr(mass_test[(y_pred > threshold) ], y_pred[(y_pred > threshold)])\n",
    "print \"Unweighted correlation of all test events passing cut with mass is\", corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(y_pred>0.5).sum()/float(y_pred.shape[0]) # much better than without class_weight training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now with Adversarial Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:17: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:29: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "def make_trainable(network, flag):\n",
    "    network.trainable = flag\n",
    "    for l in network.layers:\n",
    "        l.trainable = flag\n",
    "\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "inputs_b = Input(shape=(X_train.shape[1],))\n",
    "inputs_s = Input(shape=(X_train.shape[1],))\n",
    "\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "\n",
    "#@TODO: Gradient reversal layer, and simul training\n",
    "#@TODO: loss on only the signal, we want that to be flat\n",
    "Rx = Dx\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "Rx = Dense(32, activation=\"relu\")(Rx)\n",
    "#for i in range(20):\n",
    "#    Rx = Dense(32, activation=\"tanh\")(Rx)\n",
    "#Rx = Dense(1, activation=\"sigmoid\")(Rx) #try regression activations @TODO\n",
    "Rx = Dense(1, activation=\"relu\")(Rx)\n",
    "R = Model(input=[inputs], outputs=[Rx])\n",
    "#@TODO: loss only on background events, tanh activation, batch norm, drop out, see Andreas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:27: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:39: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.optimizers import SGD\n",
    "from keras.losses import mean_squared_error\n",
    "\n",
    "lam = 3.0 #10.0 # pivotal trade-off\n",
    "\n",
    "def make_loss_D(c):\n",
    "    def loss_D(y_true, y_pred):\n",
    "        #return c * K.binary_crossentropy(y_true, y_pred)\n",
    "        return c * K.mean(K.binary_crossentropy(y_true, y_pred), axis=-1) #!!! new keras from 2.0.7\n",
    "    return loss_D\n",
    "\n",
    "def make_loss_R(c):\n",
    "    def loss_R(z_true, z_pred):\n",
    "        return c * mean_squared_error(z_true, z_pred) ##!!! new keras from 2.0.7\n",
    "    return loss_R\n",
    "\n",
    "#opt_D = SGD()\n",
    "opt_D = \"adam\"\n",
    "D.compile(loss=[make_loss_D(c=1.0)], optimizer=opt_D)\n",
    "#D.compile(loss=\"binary_crossentropy\", optimizer=opt_D)\n",
    "\n",
    "# Train D such that R loss (its c=-lam) is also minimised, make it invariant to R\n",
    "#can we train simultaneous? grad reversal layer???\n",
    "#opt_DRf = SGD(momentum=0.0)\n",
    "opt_DRf = \"adam\"\n",
    "DRf = Model(input=[inputs], output=[D(inputs), R(inputs)])\n",
    "# R only on signal\n",
    "#DRf = Model(input=[inputs_b, inputs_s], output=[D(inputs_b),D(inputs_s), R(inputs_s)])\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "# R only on signal\n",
    "#DRf.compile(loss=[make_loss_D(c=1.0),make_loss_D(c=1.0), make_loss_R(c=-lam)], optimizer=opt_DRf)\n",
    "DRf.compile(loss=[make_loss_D(c=1.0), make_loss_R(c=-lam)], optimizer=opt_DRf)\n",
    "#DRf.compile(loss=[\"binary_crossentropy\", \"mean_squared_error\"], loss_weights=[1,-lam], optimizer=opt_DRf)\n",
    "\n",
    "#opt_DfR = SGD(momentum=0.0)\n",
    "opt_DfR = \"adam\"\n",
    "DfR = Model(input=[inputs], output=[R(inputs)])\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "#DfR.compile(loss=[make_loss_R(c=1.0)], optimizer=opt_DfR)\n",
    "DfR.compile(loss=[make_loss_R(c=lam)], optimizer=opt_DfR)\n",
    "#DfR.compile(loss=[\"mean_squared_error\"], loss_weights=[lam],optimizer=opt_DfR)\n",
    "#DfR.compile(loss=\"mean_squared_error\",optimizer=opt_DfR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(\"D\"), write_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.5409     \n",
      "Epoch 2/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.4364     \n",
      "Epoch 3/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.4210     \n",
      "Epoch 4/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.4130     \n",
      "Epoch 5/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.4060     \n",
      "Epoch 6/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.4008     \n",
      "Epoch 7/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.4009     \n",
      "Epoch 8/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3930     \n",
      "Epoch 9/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3889     \n",
      "Epoch 10/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3840     \n",
      "Epoch 11/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3771     \n",
      "Epoch 12/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3799     \n",
      "Epoch 13/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3723     \n",
      "Epoch 14/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3683     \n",
      "Epoch 15/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.3660     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f47a990>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain D\n",
    "make_trainable(R, False)\n",
    "make_trainable(D, True)\n",
    "D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=15, callbacks=[tensorboard]) # 15 epochs\n",
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10) # 10 epochs\n",
    "\n",
    "#D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167568"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.47094741, -0.87801313, -1.01689678, -0.38257515, -1.11590685,\n",
       "         0.38790233,  0.27586687, -0.05628516,  1.05072289],\n",
       "       [-0.62529195, -0.08021281,  0.25521114,  1.25405889,  1.32495307,\n",
       "         2.03881435, -0.73394482, -0.645964  , -0.37460657]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:8: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0581     \n",
      "Epoch 2/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0522     \n",
      "Epoch 3/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0529     \n",
      "Epoch 4/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0514     \n",
      "Epoch 5/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0525     \n",
      "Epoch 6/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0514     \n",
      "Epoch 7/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0527     \n",
      "Epoch 8/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0515     \n",
      "Epoch 9/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0498     \n",
      "Epoch 10/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0526     \n",
      "Epoch 11/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0518     \n",
      "Epoch 12/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0493     \n",
      "Epoch 13/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0512     \n",
      "Epoch 14/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0506     \n",
      "Epoch 15/15\n",
      "2234/2234 [==============================] - 0s - loss: 0.0534     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10ceb8e10>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrain R\n",
    "make_trainable(R, True)\n",
    "make_trainable(D, False)\n",
    "# Train with noly signal\n",
    "#DfR.fit(X_train[y_train==1], mass_train[y_train==1], sample_weight=weights_train[y_train==1], nb_epoch=5) # only signal\n",
    "#DfR.fit([X_train[y_train==1], X_train[y_train==1]], [mass_train[y_train==1],mass_train[y_train==1]], sample_weight=[weights_train[y_train==0],weights_train[y_train==1]], nb_epoch=5) # only signal\n",
    "# Train with noly signal, mask with weights=0\n",
    "DfR.fit(X_train, mass_train, sample_weight=weights_train*y_train, nb_epoch=15)#5)\n",
    "#DfR.fit(X_train, mass_train, sample_weight=weights_train, nb_epoch=5)\n",
    "\n",
    "#DfR.fit(X_train, mass_train, nb_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import adam\n",
    "DfR.compile(loss=[make_loss_R(c=lam)], optimizer=\"SGD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DfR.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DRf.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DfR.evaluate(X_test, [mass_test], sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) #/ lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_r$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f - \\lambda L_r$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "batch_size = 128\n",
    "training_iterations = 50#201\n",
    "for i in range(training_iterations):\n",
    "    l = DRf.evaluate(X_test, [y_test, mass_test], sample_weight=[weights_test,weights_test], verbose=0)\n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    losses[\"L_f\"].append(l[1][None][0]) # why none, 0? just do l[1]??\n",
    "    losses[\"L_r\"].append(-l[2][None][0])\n",
    "    print(losses[\"L_f\"][-1], losses[\"L_r\"][-1] / lam, losses[\"L_r\"][-1])\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit D\n",
    "    make_trainable(R, False)\n",
    "    make_trainable(D, True)\n",
    "    indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "    print \"DRf\"\n",
    "    DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], sample_weight=[weights_train[indices], weights_train[indices]])\n",
    "        \n",
    "    # Fit R\n",
    "    make_trainable(R, True)\n",
    "    make_trainable(D, False)\n",
    "    print \"DfR\"\n",
    "    DfR.fit(X_train, mass_train, batch_size=batch_size, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, batch_size=batch_size, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #@TODO: try grad reversal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85415437116943094"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_dc = D.predict(X_test)\n",
    "y_pred_dc = y_pred_dc.ravel()\n",
    "roc_auc_score(y_test, y_pred_dc, sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(y_pred_dc[mass_test<mass_test.mean()], weights=weights_test[mass_test<mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred_dc[mass_test>=mass_test.mean()], weights=weights_test[mass_test>=mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted correlation with mass is (0.12752753, 0.0)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred_dc)\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.93764353,  0.69847929,  0.9470982 , ...,  0.01060705,\n",
       "        0.24570423,  0.26155996], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_predict = R.predict(X_test)\n",
    "mass_predict_train = R.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21942294],\n",
       "       [ 0.20828119],\n",
       "       [ 0.2198711 ],\n",
       "       ..., \n",
       "       [ 0.1660943 ],\n",
       "       [ 0.19889244],\n",
       "       [ 0.199828  ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean true 0.19284 mean pred 0.207357\n"
     ]
    }
   ],
   "source": [
    "print \"mean true\",(mass_test[y_test==1]).mean(), \"mean pred\", np.mean(mass_predict[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median true 0.161706849933 median pred 0.208382\n"
     ]
    }
   ],
   "source": [
    "print \"median true\",(mass_test[y_test==1]).median(), \"median pred\", np.median(mass_predict[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std true 0.146229 std pred 0.0122509\n"
     ]
    }
   ],
   "source": [
    "print \"std true\",(mass_test[y_test==1]).std(), \"std pred\", np.std(mass_predict[y_test==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: mean true 0.196533 mean pred 0.208054\n"
     ]
    }
   ],
   "source": [
    "print \"Train: mean true\",(mass_train[y_train==1]).mean(), \"mean pred\", np.mean(mass_predict_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: median true 0.165431588888 median pred 0.208938\n"
     ]
    }
   ],
   "source": [
    "print \"Train: median true\",(mass_train[y_train==1]).median(), \"median pred\", np.median(mass_predict_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: std true 0.14876 std pred 0.0117646\n"
     ]
    }
   ],
   "source": [
    "print \"Train: std true\",(mass_train[y_train==1]).std(), \"std pred\", np.std(mass_predict_train[y_train==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21942294],\n",
       "       [ 0.20828119],\n",
       "       [ 0.2198711 ],\n",
       "       ..., \n",
       "       [ 0.1660943 ],\n",
       "       [ 0.19889244],\n",
       "       [ 0.199828  ]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220160/221190 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.075736412211899e-05"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DfR.evaluate(X_test, [mass_test], sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cea2fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mass_predict, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_test, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#doesnt change after adversrial training.. should get worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLyISuP8H2KG8ge5U5dYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ce9fed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mass_predict[y_test==1], weights=weights_test[y_test==1], bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_test[y_test==1], weights=weights_test[y_test==1], bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(plt.titlelt.title(\"VBF Events\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc_train = D.predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_pred_test_sig = [weights_train[(y_train ==1) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "#int_pred_test_bkg = [weights_train[(y_train ==0) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "\n",
    "int_pred_dc_test_sig = [weights_test[(y_test ==1) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_dc_test_bkg = [weights_test[(y_test ==0) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10f550f10>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZAkFuohIllCgi4hkif8PMG0OY2vPI5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f599a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_sig)\n",
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import amsasimov\n",
    "vamsasimov_dc = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_dc_test_sig,int_pred_dc_test_bkg)]\n",
    "significance_dc = max(vamsasimov_dc)\n",
    "threshold_dc = np.linspace(0,1,num=50)[ np.array(vamsasimov_dc).argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.603669469483721, 0.8571428571428571)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "significance_dc, threshold_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x10d71db90>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwl1EJAMp3EVEMtD/BzxSMkGB11zfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f8608d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),vamsasimov_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfBGRHPE/y8Z0OOukFUYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f8a5290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from util_func import compare_train_test\n",
    "compare_train_test(y_pred_dc_train, y_train, y_pred_dc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGevMass(mass):\n",
    "    return np.exp (mass * (mass_max - mass_min) + mass_min)\n",
    "plt.hist(getGevMass(mass_test), weights=weights_test, bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score > \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Mass Distribution (s+b)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "temp = np.zeros((len(mass_test),), dtype=[('mass',np.float64),('weight',np.float64),('NN_score',np.float64) ])\n",
    "temp['mass'] = np.array(getGevMass(mass_test))\n",
    "temp['weight'] = np.array(weights_test)\n",
    "temp['NN_score'] = np.array(y_pred_dc)\n",
    "\n",
    "from root_numpy import array2tree\n",
    "tree_dc = array2tree(temp)\n",
    "\n",
    "from ROOT import TEfficiency, TH1F\n",
    "bins = 50\n",
    "scoremin = temp['mass'].min()\n",
    "scoremax = temp['mass'].max()\n",
    "hpreselect_dc = TH1F(\"hpreselect_dc\", \"mass distribution before NN\", bins, scoremin, scoremax)\n",
    "hpreselect_dc.Sumw2()\n",
    "hD = TH1F(\"hD\", \"mass distribution for D Score > \" + str(threshold_dc), bins, scoremin, scoremax)\n",
    "hD.Sumw2()\n",
    "#tree.Project(\"hpreselect\", \"mass\", \"weight\" ) #Tefficiency can;t do weights\n",
    "tree_dc.Project(\"hpreselect_dc\", \"mass\" )\n",
    "#tree.Project(\"hNN\", \"mass\", \"weight*(NN_score>=\" +str(threshold) + \")\" )\n",
    "tree_dc.Project(\"hD\", \"mass\", \"(NN_score>=\" +str(threshold_dc) + \")\" )\n",
    "\n",
    "print TEfficiency.CheckConsistency(hD, hpreselect_dc)\n",
    "pEff_dc = TEfficiency(hD, hpreselect_dc)\n",
    "\n",
    "from ROOT import TCanvas\n",
    "c_dc = TCanvas(\"dcCanvas\",\"dc Canvas\",800,350)\n",
    "pEff_dc.SetTitle(\"Efficiency: Pre-selection vs Post D Selection;Mass (GeV) ;#epsilon\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pEff_dc.Draw(\"AP\")\n",
    "#ROOT.enableJSVis()\n",
    "c_dc.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mass_predict !=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again with adverserial training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(i, losses):\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(plt.gcf())\n",
    "\n",
    "    ax1 = plt.subplot(311)   \n",
    "    values = np.array(losses[\"L_f\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f$\", color=\"blue\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax2 = plt.subplot(312, sharex=ax1) \n",
    "    values = np.array(losses[\"L_r\"]) #/ lam\n",
    "    plt.plot(range(len(values)), values, label=r\"$\\lambda L_r$\", color=\"green\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    ax3 = plt.subplot(313, sharex=ax1)\n",
    "    values = np.array(losses[\"L_f - L_r\"])\n",
    "    plt.plot(range(len(values)), values, label=r\"$L_f - \\lambda L_r$\", color=\"red\")  \n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = {\"L_f\": [], \"L_r\": [], \"L_f - L_r\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "training_iterations = 201 #50\n",
    "for i in range(training_iterations):\n",
    "    #l = DRf.evaluate(X_test, [y_test, mass_test], sample_weight=[weights_test,weights_test], verbose=0)  \n",
    "    l = DRf.evaluate(X_train, [y_train, mass_train], sample_weight=[weights_train,weights_train], verbose=0)  \n",
    "    losses[\"L_f - L_r\"].append(l[0][None][0])\n",
    "    losses[\"L_f\"].append(l[1][None][0]) # why none, 0? just do l[1]??\n",
    "    losses[\"L_r\"].append(-l[2][None][0]) # the - cancels the - in loss -lam\n",
    "    print(losses[\"L_f\"][-1], losses[\"L_r\"][-1] / lam, losses[\"L_r\"][-1])\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        plot_losses(i, losses)\n",
    "\n",
    "    # Fit D\n",
    "    make_trainable(R, False)\n",
    "    make_trainable(D, True)\n",
    "    indices = np.random.permutation(len(X_train))[:batch_size]\n",
    "    print \"DRf\"\n",
    "    #use iloc\n",
    "    ##DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], sample_weight=[weights_train[indices], weights_train[indices]])\n",
    "    DRf.train_on_batch(X_train[indices], [y_train[indices], mass_train[indices]], sample_weight=[weights_train[indices], weights_train[indices]*y_train[indices]])\n",
    "    #@TODO: Make explicite masking with weights, y_train mught become multiclass later\n",
    "    \n",
    "    # Fit R\n",
    "    make_trainable(R, True)\n",
    "    make_trainable(D, False)\n",
    "    print \"DfR\"\n",
    "    #masking background events\n",
    "    DfR.fit(X_train, mass_train, batch_size=batch_size, sample_weight=weights_train*y_train, nb_epoch=1, verbose=1)\n",
    "    ##DfR.fit(X_train, mass_train, batch_size=batch_size, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, batch_size=batch_size, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, nb_epoch=1, verbose=1)\n",
    "    #DfR.fit(X_train, mass_train, sample_weight=weights_train, nb_epoch=1, verbose=1)\n",
    "    #@TODO: try grad reversal layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred_dc = D.predict(X_test)\n",
    "y_pred_dc = y_pred_dc.ravel()\n",
    "roc_auc_score(y_test, y_pred_dc, sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plt.hist(y_pred_dc[mass_test<mass_test.mean()], weights=weights_test[mass_test<mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred_dc[mass_test>=mass_test.mean()], weights=weights_test[mass_test>=mass_test.mean()], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred_dc)\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mass_predict = R.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DfR.evaluate(X_test, [mass_test], sample_weight=weights_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mass_predict, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"Predicted\")\n",
    "plt.hist(mass_test, weights=weights_test, bins=50, histtype=\"step\", normed=1, label=\"True\")\n",
    "\n",
    "#plt.ylim(0, 5)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#doesnt change after adversrial training.. should get worse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dc_train = D.predict(X_train).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#int_pred_test_sig = [weights_train[(y_train ==1) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "#int_pred_test_bkg = [weights_train[(y_train ==0) & (y_pred_train > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "\n",
    "int_pred_dc_test_sig = [weights_test[(y_test ==1) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_dc_test_bkg = [weights_test[(y_test ==0) & (y_pred_dc > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_sig)\n",
    "plt.plot(np.linspace(0,1,num=50),int_pred_dc_test_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import amsasimov\n",
    "vamsasimov_dc = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_dc_test_sig,int_pred_dc_test_bkg)]\n",
    "significance_dc = max(vamsasimov_dc)\n",
    "threshold_dc = np.linspace(0,1,num=50)[ np.array(vamsasimov_dc).argmax() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "significance_dc, threshold_dc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.linspace(0,1,num=50),vamsasimov_dc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util_func import compare_train_test\n",
    "compare_train_test(y_pred_dc_train, y_train, y_pred_dc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGevMass(mass):\n",
    "    return np.exp (mass * (mass_max - mass_min) + mass_min)\n",
    "plt.hist(getGevMass(mass_test), weights=weights_test, bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Preselection\")\n",
    "plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Mass Distribution (s+b)\")\n",
    "#plt.ylim(0, 4)\n",
    "plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But R looks at all events, not just the ones with high score so it tries to \n",
    "#also predict the mass of background. It shouldnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test,y=y_pred_dc, weights=weights_test, bins=50, label=\"Preselection\")\n",
    "#plt.hist2d(x=getGevMass(mass_test),y=y_pred_dc, weights=weights_test, bins=50, normed=1, label=\"Preselection\")\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of all Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test[y_pred_dc >= threshold_dc],y=y_pred_dc[y_pred_dc >= threshold_dc], weights=weights_test[y_pred_dc >= threshold_dc], bins=50, label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of Score >= \" + str(threshold_dc)+\" Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test[y_test ==1],y=y_pred_dc[y_test ==1], weights=weights_test[y_test ==1], bins=50, label=\"True VBF Events\")\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of Score >= \" + str(threshold_dc)+\" Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist2d(x=mass_test[y_pred_dc < threshold_dc],y=y_pred_dc[y_pred_dc < threshold_dc], weights=weights_test[y_pred_dc < threshold_dc], bins=50, label=\"Score < \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc >= threshold_dc]), weights=weights_test[y_pred_dc >= threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score >= \" + str(threshold_dc))\n",
    "#plt.hist(getGevMass(mass_test[y_pred_dc < threshold_dc]), weights=weights_test[y_pred_dc < threshold_dc], bins=50, histtype=\"step\", normed=1, range=(220, 2000), label=\"Score < \" + str(threshold_dc))\n",
    "\n",
    "plt.title(\"Score vs Mass of Score < \" + str(threshold_dc)+\" Events\")\n",
    "#plt.ylim(0, 4)\n",
    "#plt.xlim(200, 1200)\n",
    "plt.xlabel(\"mass GeV\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.zeros((len(mass_test),), dtype=[('mass',np.float64),('weight',np.float64),('NN_score',np.float64) ])\n",
    "temp['mass'] = np.array(getGevMass(mass_test))\n",
    "temp['weight'] = np.array(weights_test)\n",
    "temp['NN_score'] = np.array(y_pred_dc)\n",
    "\n",
    "from root_numpy import array2tree\n",
    "tree_dc = array2tree(temp)\n",
    "\n",
    "from ROOT import TEfficiency, TH1F\n",
    "bins = 50\n",
    "scoremin = temp['mass'].min()\n",
    "scoremax = temp['mass'].max()\n",
    "hpreselect_dc = TH1F(\"hpreselect_dc\", \"mass distribution before NN\", bins, scoremin, scoremax)\n",
    "hpreselect_dc.Sumw2()\n",
    "hD = TH1F(\"hD\", \"mass distribution for D Score > \" + str(threshold_dc), bins, scoremin, scoremax)\n",
    "hD.Sumw2()\n",
    "#tree.Project(\"hpreselect\", \"mass\", \"weight\" ) #Tefficiency can;t do weights\n",
    "tree_dc.Project(\"hpreselect_dc\", \"mass\" )\n",
    "#tree.Project(\"hNN\", \"mass\", \"weight*(NN_score>=\" +str(threshold) + \")\" )\n",
    "tree_dc.Project(\"hD\", \"mass\", \"(NN_score>=\" +str(threshold_dc) + \")\" )\n",
    "\n",
    "print TEfficiency.CheckConsistency(hD, hpreselect_dc)\n",
    "pEff_dc = TEfficiency(hD, hpreselect_dc)\n",
    "\n",
    "from ROOT import TCanvas\n",
    "c_dc = TCanvas(\"dcCanvas\",\"dc Canvas\",800,350)\n",
    "pEff_dc.SetTitle(\"Efficiency: Pre-selection vs Post D Selection;Mass (GeV) ;#epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pEff_dc.Draw(\"AP\")\n",
    "#ROOT.enableJSVis()\n",
    "c_dc.Draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mass_predict !=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @NOW: Try multiclass bin 'regression' instead\n",
    "# Tensorboard\n",
    "# find out why nan if I use indices but not train_test_split\n",
    "# try to just make a NN map 1 to 2, 2 to 6, 3 to 9 memorise it\n",
    "\n",
    "#: inject mass correlation and see if R learns anything at all. Find the elephant\n",
    "# R is sometimes learning somtimes not.. why.. reproducible problem?\n",
    "# the D without adverserial training is asmost same as after adverserial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# sometimes training R gives 0 for every event... why. not reproducible?\n",
    "# why is the loss look decreasing further on pivot training, its not actually cuz auc is worse\n",
    "#@TODO: Compare AUC/significance with qq, without qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Victor:\n",
    "# pivot not working well\n",
    "# V: Try to overfit on 100 samples: find elephant problems\n",
    "# regression activation, loss function?\n",
    "# V: Its okay trial and error | andreas did classification\n",
    "# loss of r is changing at a lower level, maybe subtract off the first loss?\n",
    "# V: maybe\n",
    "# grad reversal layer\n",
    "# V: simultaneous could be better\n",
    "# why is the loss look decreasing further on pivot training, its not actually cuz auc is worse\n",
    "# V: Maybe you need to let pre-training converge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip2 install jupyter_contrib_nbextensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ams loss function: celver way to impliment, if else wont work: like makeing soft cuts\n",
    "# how close to 0, how close to 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "635px",
    "left": "0px",
    "right": "1070px",
    "top": "110px",
    "width": "128px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
