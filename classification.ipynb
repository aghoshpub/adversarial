{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load signal, backgound data\n",
    "vbf_events = pd.read_hdf(\"../MC_Prod_v12/vbf_events.hdf\", \"vbf\")\n",
    "ggf_events = pd.read_hdf(\"../MC_Prod_v12/ggF_events.hdf\", \"ggF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vbf_events[\"class\"] = 1\n",
    "ggf_events[\"class\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([vbf_events, ggf_events])\n",
    "#print data.isnull().values.any()\n",
    "#data.describe()\n",
    "data = data.sample(frac=1).reset_index(drop=True) #shuffle the events\n",
    "target = data[\"class\"]\n",
    "mass = data[\"m4l_fsr\"]\n",
    "weights = data[\"weight_couplings\"]\n",
    "del data[\"class\"]\n",
    "del data[\"m4l_fsr\"]\n",
    "del data[\"weight_couplings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dijet_invmass</th>\n",
       "      <th>dijet_deltaeta</th>\n",
       "      <th>eta_zepp_ZZ</th>\n",
       "      <th>min_dR_jZ</th>\n",
       "      <th>leading_jet_width</th>\n",
       "      <th>subleading_jet_width</th>\n",
       "      <th>jet_pt[0]</th>\n",
       "      <th>jet_pt[1]</th>\n",
       "      <th>max(50,pt4ljj_unconstrained)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>356.650330</td>\n",
       "      <td>1.669236</td>\n",
       "      <td>0.888165</td>\n",
       "      <td>0.645989</td>\n",
       "      <td>0.066390</td>\n",
       "      <td>0.065942</td>\n",
       "      <td>160.391830</td>\n",
       "      <td>107.271393</td>\n",
       "      <td>81.475380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>992.272217</td>\n",
       "      <td>6.654521</td>\n",
       "      <td>1.400082</td>\n",
       "      <td>2.667042</td>\n",
       "      <td>0.184306</td>\n",
       "      <td>0.061050</td>\n",
       "      <td>40.699841</td>\n",
       "      <td>31.229019</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1492.957275</td>\n",
       "      <td>5.679202</td>\n",
       "      <td>0.346004</td>\n",
       "      <td>1.832507</td>\n",
       "      <td>0.103212</td>\n",
       "      <td>0.072501</td>\n",
       "      <td>147.309769</td>\n",
       "      <td>52.006111</td>\n",
       "      <td>94.640076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>362.621246</td>\n",
       "      <td>3.135902</td>\n",
       "      <td>0.380532</td>\n",
       "      <td>1.979456</td>\n",
       "      <td>0.038277</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>106.111481</td>\n",
       "      <td>50.047699</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>396.182526</td>\n",
       "      <td>2.721596</td>\n",
       "      <td>1.753255</td>\n",
       "      <td>1.458591</td>\n",
       "      <td>0.039014</td>\n",
       "      <td>0.057238</td>\n",
       "      <td>102.591476</td>\n",
       "      <td>90.672752</td>\n",
       "      <td>62.286587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dijet_invmass  dijet_deltaeta  eta_zepp_ZZ  min_dR_jZ  leading_jet_width  \\\n",
       "0     356.650330        1.669236     0.888165   0.645989           0.066390   \n",
       "1     992.272217        6.654521     1.400082   2.667042           0.184306   \n",
       "2    1492.957275        5.679202     0.346004   1.832507           0.103212   \n",
       "3     362.621246        3.135902     0.380532   1.979456           0.038277   \n",
       "4     396.182526        2.721596     1.753255   1.458591           0.039014   \n",
       "\n",
       "   subleading_jet_width   jet_pt[0]   jet_pt[1]  max(50,pt4ljj_unconstrained)  \n",
       "0              0.065942  160.391830  107.271393                     81.475380  \n",
       "1              0.061050   40.699841   31.229019                     50.000000  \n",
       "2              0.072501  147.309769   52.006111                     94.640076  \n",
       "3              0.006525  106.111481   50.047699                     50.000000  \n",
       "4              0.057238  102.591476   90.672752                     62.286587  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/sklearn/model_selection/_split.py:2010: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test, mass_train, mass_test, weights_train, weights_test = \\\n",
    "    train_test_split(data, target, mass, weights, train_size=0.75)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:12: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "#from keras.optimizers import SGD\n",
    "\n",
    "#@TODO: check other activations in Andreas, Gilles pivot\n",
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "Dx = Dense(32, activation=\"relu\")(inputs)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(32, activation=\"relu\")(Dx)\n",
    "Dx = Dense(1, activation=\"sigmoid\")(Dx)\n",
    "D = Model(input=[inputs], output=[Dx])\n",
    "D.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train *=1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(weights_train ==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(y, smooth_factor=0):\n",
    "    \"\"\"\n",
    "    Returns the weights for each class based on the frequencies of the samples\n",
    "    :param smooth_factor: factor that smooths extremely uneven weights\n",
    "    :param y: list of true labels (the labels must be hashable)\n",
    "    :return: dictionary with the weight for each class\n",
    "    \"\"\"\n",
    "    from collections import Counter\n",
    "    counter = Counter(y)\n",
    "\n",
    "    if smooth_factor > 0:\n",
    "        p = max(counter.values()) * smooth_factor\n",
    "        for k in counter.keys():\n",
    "            counter[k] += p\n",
    "\n",
    "    majority = max(counter.values())\n",
    "\n",
    "    return {cls: float(majority) / count for cls, count in counter.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel_launcher.py:3: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7617     \n",
      "Epoch 2/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7342     \n",
      "Epoch 3/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7292     \n",
      "Epoch 4/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7255     \n",
      "Epoch 5/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7235     \n",
      "Epoch 6/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7216     \n",
      "Epoch 7/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7199     \n",
      "Epoch 8/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7183     \n",
      "Epoch 9/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7176     \n",
      "Epoch 10/10\n",
      "72115/72115 [==============================] - 5s - loss: 0.7152     \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x116d60790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#D.fit(X_train, y_train, sample_weight=weights_train, nb_epoch=10) #nan loss\n",
    "#D.fit(X_train, y_train, nb_epoch=10) #unweighted training !!! @TODO: weighted\n",
    "D.fit(X_train, y_train, nb_epoch=10, class_weight=get_class_weights(y_train)) #unweighted training !!! @TODO: weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 6.374475917783005, 1: 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8909870274362397"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_pred = D.predict(X_test)\n",
    "y_pred = y_pred.ravel()\n",
    "roc_auc_score(y_true=y_test, y_score=y_pred, sample_weight=weights_test)\n",
    "#roc_auc_score(y_true=y_test, y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.09728482,  0.07320319,  0.79686791, ...,  0.99798489,\n",
       "        0.97133696,  0.96265858], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    96154.000000\n",
       "mean       409.301788\n",
       "std        219.603745\n",
       "min        220.001450\n",
       "25%        269.205750\n",
       "50%        338.666626\n",
       "75%        467.695061\n",
       "max       3806.846436\n",
       "Name: m4l_fsr, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b430a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred[mass_test<409], weights=weights_test[mass_test<409], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "plt.hist(y_pred[mass_test>=409], weights=weights_test[mass_test>=409], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "#plt.hist(y_pred[mass_test<409], bins=50, histtype=\"step\", normed=1, label=\"Low\")\n",
    "#plt.hist(y_pred[mass_test>=409], bins=50, histtype=\"step\", normed=1, label=\"High\")\n",
    "\n",
    "\n",
    "plt.ylim(0, 30)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted correlation with mass is (0.1460292, 1.0901637514020769e-114)\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr = pearsonr(mass_test, y_pred.ravel())\n",
    "print \"Unweighted correlation with mass is\", corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now first put weights or itll just get all vbf correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72028786555181168"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y_pred>0.5).sum()/float(y_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with weights\n",
    "# train with equalized weights\n",
    "# shuffle dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
